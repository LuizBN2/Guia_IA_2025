{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e013f04-0a79-4104-935e-2f26fa67525b",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <h1 style=\"color: orange;\">Anexo 25</h1>\n",
    "    <h3>Proyecto 25: Generador de Resumen BiLSTM en Streamlit</h3>\n",
    "    <hr/>\n",
    "    <p style=\"text-align: right;\">Mg. Luis Felipe Bustamante Narv√°ez</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8adcd72-f971-45df-8d14-57436e0c0754",
   "metadata": {},
   "source": [
    "Este proyecto es el **<span style=\"color:orange\">Proyecto Final</span>**, en el cu√°l dise√±amos el modelo con **<span style=\"color:orange\">RNN's</span>** implementado en **<span style=\"color:orange\">Streamlit</span>**, a partir de la generaci√≥n del archivo **<span style=\"color:orange\">.py</span>**, para su correcta ejecuci√≥n y despliegue, el cual se encuentra en el enlace:  \n",
    "\n",
    "üîó [**bilstm-app.streamlit.app**](https://bilstm-summaty-text-25.streamlit.app/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb3f790-a5a5-4c9e-ac83-e20fb885c816",
   "metadata": {},
   "source": [
    "## Arquitectura del Proyecto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d1aa25-e91c-4b4a-91bf-bcfd37a73582",
   "metadata": {},
   "source": [
    "```\n",
    "üì¶ resumen_bilstm/\n",
    "‚îú‚îÄ‚îÄ üìÇ .streamlit/\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ config.toml\n",
    "‚îú‚îÄ‚îÄ üìÇ data/\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ df_total.csv\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ metricas_entrenamiento_25.csv\n",
    "‚îú‚îÄ‚îÄ üìÇ images/\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ modelo_coloreado.dot\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ modelo_coloreado.png\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ modelo_resumen_bilstm_25.png\n",
    "‚îú‚îÄ‚îÄ üìÇ models/\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ historial_entrenamiento_25.pkl\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ modelo_resumen_bilstm_25.keras\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ tokenizer_resumen_25.pkl\n",
    "‚îú‚îÄ‚îÄ üìÇ pages/\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ __init__.py \n",
    "‚îÇ   ‚îî‚îÄ‚îÄ entrenamiento_modelo_25.py \n",
    "‚îÇ   ‚îî‚îÄ‚îÄ resumen_modelo_25.py \n",
    "‚îÇ   ‚îî‚îÄ‚îÄ resumir_texto_manual_25.py \n",
    "‚îÇ   ‚îî‚îÄ‚îÄ visualizar_modelo_25.py\n",
    "‚îú‚îÄ‚îÄ üìÇ utils/\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ utils.py \n",
    "‚îú‚îÄ‚îÄ app_resumen_25.py\n",
    "‚îú‚îÄ‚îÄ requirements.txt```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159e5e29-c39e-4775-bc8a-d4a83d3f51b1",
   "metadata": {},
   "source": [
    "#### El contenido de las carpetas, **<span style=\"color:orange\">models</span>** e **<span style=\"color:orange\">images</span>** se generan una vez se ejecute el **<span style=\"color:orange\">streamlit run app_resumen_25.py</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f92b6e-ca3b-41cf-8476-e1bb7e13e3c9",
   "metadata": {},
   "source": [
    "## .streamlit (<span style=\"color:orange\">config.toml</span>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbfad130-1972-43cb-a82c-537452220693",
   "metadata": {},
   "outputs": [],
   "source": [
    "[theme]\n",
    "base=\"light\"\n",
    "primaryColor=\"#e42ae3\"\n",
    "secondaryBackgroundColor=\"#c5b3d4\"\n",
    "textColor=\"#4c065e\"\n",
    "\n",
    "[server]\n",
    "runOnSave = true\n",
    "\n",
    "[client]\n",
    "showSidebarNavigation = false\n",
    "\n",
    "[ui]\n",
    "hideSidebarNav = false\n",
    "sidebarState = \"expanded\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110e7b7b-2bd4-4e55-8688-3af56db06237",
   "metadata": {},
   "source": [
    "## pages/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7044c2e9-92d0-4679-ac26-911196c9b824",
   "metadata": {},
   "source": [
    "### <span style=\"color:orange\">entrenamiento_modelo_25.py</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3c2742-7235-431b-a200-f63547c8cb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import pickle\n",
    "import os\n",
    "import nltk\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense\n",
    "from tensorflow.keras.models import save_model\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "\n",
    "#st.set_page_config(page_title=\"Resumen de Noticias\", layout=\"wide\")\n",
    "\n",
    "from utils.utils import mostrar_firma_sidebar\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('spanish'))\n",
    "\n",
    "\n",
    "\n",
    "st.title(\"üîÅ Reentrenar modelo BiLSTM para resumen de noticias\")\n",
    "\n",
    "def sidebar():\n",
    "    with st.sidebar:\n",
    "        st.header(\"üöÄ Entrenamiento del modelo\")\n",
    "        st.markdown('---')\n",
    "    \n",
    "        st.subheader(\"üìä M√©tricas del Modelo\")\n",
    "\n",
    "        metrics_path = \"data/metricas_entrenamiento_25.csv\"\n",
    "        if os.path.exists(metrics_path):\n",
    "            metricas_df = pd.read_csv(metrics_path)\n",
    "            #st.info(metricas_df)\n",
    "            #st.line_chart(metricas_df[['loss', 'val_loss']])\n",
    "            st.line_chart(metricas_df[['accuracy', 'val_accuracy']])\n",
    "        else:\n",
    "            st.info(\"No se encontraron m√©tricas guardadas.\")\n",
    "\n",
    "        st.page_link('app_resumen_25.py', label='**üè† P√°gina Principal**')\n",
    "        st.page_link('pages/visualizar_modelo_25.py', label='**üß± Arquitectura**')\n",
    "        st.page_link('pages/resumir_texto_manual_25.py', label='**üìù Tu resumen**')\n",
    "        mostrar_firma_sidebar()\n",
    "        \n",
    "\n",
    "# Funci√≥n para limpiar texto y eliminar stopwords\n",
    "def limpiar_y_filtrar(texto):\n",
    "    # Solo letras, min√∫sculas\n",
    "    texto = re.sub(r'[^a-zA-Z√°√©√≠√≥√∫√Å√â√ç√ì√ö√±√ë√º√ú\\s]', '', texto)\n",
    "    palabras = texto.lower().split()\n",
    "    palabras_filtradas = [p for p in palabras if p not in stop_words]\n",
    "    return ' '.join(palabras_filtradas)\n",
    "\n",
    "\n",
    "#funci√≥n de entrenamiento\n",
    "def entrenamiento(epochs):\n",
    "    print('hola')\n",
    "    # Bot√≥n de entrenamiento\n",
    "    \n",
    "    st.info(\"Cargando datos y procesando...\")\n",
    "\n",
    "    df = pd.read_csv(\"data/df_total.csv\", encoding='utf-8')\n",
    "    docs = df['news'].dropna().tolist()\n",
    "\n",
    "    # Crear dataset etiquetado\n",
    "    X, y = [], []\n",
    "    for doc in docs:\n",
    "        oraciones = nltk.sent_tokenize(doc, language='spanish')\n",
    "        if len(oraciones) < 4:\n",
    "            continue\n",
    "        for i, oracion in enumerate(oraciones):\n",
    "            X.append(oracion)\n",
    "            y.append(1 if i < 3 else 0)\n",
    "\n",
    "    # Tokenizaci√≥n\n",
    "    # Aplicar limpieza a todos los textos\n",
    "    X_filtrado = [limpiar_y_filtrar(oracion) for oracion in X]\n",
    "\n",
    "    tokenizer = Tokenizer(num_words=num_words, oov_token=\"<OOV>\")\n",
    "    tokenizer.fit_on_texts(X_filtrado)\n",
    "    sequences = tokenizer.texts_to_sequences(X_filtrado)\n",
    "    X_pad = pad_sequences(sequences, \n",
    "                          maxlen=max_len, \n",
    "                          padding='post', \n",
    "                          truncating='post')\n",
    "    y = np.array(y)\n",
    "\n",
    "    # Train/test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_pad, \n",
    "                                                        y, \n",
    "                                                        test_size=0.2, \n",
    "                                                        random_state=42\n",
    "                                                       )\n",
    "\n",
    "    # Modelo\n",
    "    modelo = Sequential()\n",
    "    modelo.add(Embedding(input_dim=num_words, \n",
    "                         output_dim=128, \n",
    "                         input_length=max_len))\n",
    "    modelo.add(Bidirectional(LSTM(64, return_sequences=False)))\n",
    "    modelo.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    modelo.compile(optimizer='adam', \n",
    "                   loss='binary_crossentropy', \n",
    "                   metrics=['accuracy'])\n",
    "\n",
    "    st.info(\"Entrenando modelo...\")\n",
    "    # Barra de progreso y estado\n",
    "    progress_bar = st.progress(0)\n",
    "    status_text = st.empty()\n",
    "\n",
    "    class StreamlitProgressCallback(Callback):\n",
    "        def __init__(self, epochs):\n",
    "            super().__init__()\n",
    "            self.epochs = epochs\n",
    "\n",
    "        def on_epoch_end(self, epoch, logs=None):\n",
    "            progress = int((epoch + 1) / self.epochs * 100)\n",
    "            progress_bar.progress(progress)\n",
    "            status_text.text(f\"√âpoca {epoch + 1}/{self.epochs} completada\")\n",
    "    history = modelo.fit(\n",
    "                        X_train, \n",
    "                        y_train, \n",
    "                        epochs=epochs, \n",
    "                        batch_size=batch_size, \n",
    "                        validation_data=(X_test, y_test), \n",
    "                        verbose=0,\n",
    "                        callbacks=[StreamlitProgressCallback(epochs)]\n",
    "                        )\n",
    "    \n",
    "    st.success(\"Entrenamiento finalizado ‚úÖ\")\n",
    "\n",
    "    # Mostrar resultados\n",
    "    df_hist = pd.DataFrame(history.history)\n",
    "    st.subheader(\"üìà M√©tricas del entrenamiento\")\n",
    "    st.line_chart(df_hist[['loss', 'val_loss']])\n",
    "    st.line_chart(df_hist[['accuracy', 'val_accuracy']])\n",
    "\n",
    "    # Guardar m√©tricas temporalmente\n",
    "    df_hist.to_csv(\"data/metricas_entrenamiento_25.csv\", index=False)\n",
    "    modelo_g = save_model(modelo, \"models/modelo_resumen_bilstm_25.keras\")\n",
    "    with open(\"models/tokenizer_resumen_25.pkl\", \"wb\") as f:\n",
    "        pickle.dump(tokenizer, f)\n",
    "    with open(\"models/historial_entrenamiento_25.pkl\", \"wb\") as g:\n",
    "        pickle.dump(history.history, g)\n",
    "    \n",
    "    if st.button('‚úÖ Aceptar'):\n",
    "        st.rerun()\n",
    "    return modelo\n",
    "\n",
    "\n",
    "# Par√°metros\n",
    "num_words = 10000\n",
    "max_len = 40\n",
    "batch_size = 32\n",
    "sidebar()\n",
    "\n",
    "# Epochs por slider\n",
    "epochs = st.slider(\"Selecciona la cantidad de √©pocas\", \n",
    "                   min_value=1, \n",
    "                   max_value=20, \n",
    "                   value=5\n",
    "                  )\n",
    "\n",
    "if st.button(\"üöÄ Entrenar modelo\"):\n",
    "    entrenamiento(epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c9b806-0d34-4f31-bedd-b8c9c4c10371",
   "metadata": {},
   "source": [
    "### <span style=\"color:orange\">resumen_modelo_25.py</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5134da22-58b1-4f7f-b8af-3949c87c92a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "from pages.entrenamiento_modelo_25 import limpiar_y_filtrar\n",
    "\n",
    "def resumir_noticia(noticia, modelo, tokenizer, umbral, max_oraciones, max_len=50):\n",
    "    # Dividir en oraciones y limpiar\n",
    "    oraciones = [s.strip() for s in nltk.sent_tokenize(noticia, language='spanish') \\\n",
    "                 if len(s.strip()) > 0]\n",
    "    \n",
    "    # Truncar si hay demasiadas oraciones\n",
    "    if len(oraciones) > max_oraciones:\n",
    "        oraciones = oraciones[:max_oraciones]\n",
    "    \n",
    "    # Preprocesar oraciones\n",
    "    X_filtrado = [limpiar_y_filtrar(oracion) for oracion in oraciones]\n",
    "    \n",
    "    # Tokenizar y rellenar\n",
    "    secuencias = tokenizer.texts_to_sequences(oraciones)\n",
    "    padded = pad_sequences(secuencias, \n",
    "                           maxlen=max_len, \n",
    "                           padding='post', \n",
    "                           truncating='post'\n",
    "                          )\n",
    "    \n",
    "    # Predecir con batch_size\n",
    "    predicciones = modelo.predict(padded, batch_size=32, verbose=0)\n",
    "    \n",
    "    # Seleccionar oraciones relevantes\n",
    "    resumen = [oraciones[i] for i in range(len(oraciones)) if predicciones[i] >= umbral]\n",
    "    \n",
    "    return resumen, X_filtrado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c85522f-4a81-44fc-bf6c-33137e2b1a15",
   "metadata": {},
   "source": [
    "### <span style=\"color:orange\">resumir_texto_manual_25.py</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427fd6a6-6309-493c-888a-65ab2cf67333",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import pickle\n",
    "from tensorflow.keras.models import load_model\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "st.set_page_config(page_title=\"Resumen de Noticias\", layout=\"wide\")\n",
    "\n",
    "from pages.resumen_modelo_25 import resumir_noticia\n",
    "from utils.utils import mostrar_firma_sidebar\n",
    "\n",
    "st.title(\"üìù Ingresar texto para resumir\")\n",
    "\n",
    "# ------------------ Sidebar ------------------\n",
    "with st.sidebar:\n",
    "    st.header(\"‚öôÔ∏è Par√°metros\")\n",
    "    umbral = st.slider(\"Ajustar umbral de relevancia\", \n",
    "                       min_value=0.1, \n",
    "                       max_value=0.9, \n",
    "                       value=0.5, \n",
    "                       step=0.05\n",
    "                      )\n",
    "    max_oraciones = st.slider(\"Limitar n√∫mero de oraciones a procesar\", \n",
    "                              min_value=10, \n",
    "                              max_value=200, \n",
    "                              value=100, \n",
    "                              step=10\n",
    "                             )\n",
    "    st.page_link('app_resumen_25.py', label='**üè† P√°gina Principal**')\n",
    "    st.page_link('pages/entrenamiento_modelo_25.py', label='**üöÄ Reentrenamiento**')\n",
    "    st.page_link('pages/visualizar_modelo_25.py', label='**üß± Arquitectura**')\n",
    "    mostrar_firma_sidebar()\n",
    "\n",
    "# ------------------ Cargar modelo y tokenizer ------------------\n",
    "modelo = load_model(\"models/modelo_resumen_bilstm_25.keras\", compile=False)\n",
    "\n",
    "with open(\"models/tokenizer_resumen_25.pkl\", \"rb\") as f:\n",
    "    tokenizer = pickle.load(f)\n",
    "\n",
    "# ------------------ Entrada de texto ------------------\n",
    "st.subheader(\"‚úèÔ∏è Escribe o pega un texto\")\n",
    "texto_usuario = st.text_area(\"Introduce aqu√≠ la noticia o el texto\\\n",
    "                            completo que deseas resumir:\", height=300)\n",
    "\n",
    "if st.button(\"üìå Generar Resumen\"):\n",
    "    if texto_usuario.strip():\n",
    "        resumen, palabras_clave = resumir_noticia(texto_usuario, \n",
    "                                                  modelo, \n",
    "                                                  tokenizer, \n",
    "                                                  umbral, \n",
    "                                                  max_oraciones\n",
    "                                                 )\n",
    "        st.subheader(\"üìù Resumen Generado\")\n",
    "        if resumen:\n",
    "            for i, oracion in enumerate(resumen, 1):\n",
    "                st.markdown(f\"{oracion}\")\n",
    "        else:\n",
    "            st.warning(\"‚ö†Ô∏è No se encontraron oraciones relevantes para este umbral.\")\n",
    "        \n",
    "         # ------------------ WordCloud ------------------\n",
    "        if palabras_clave:\n",
    "            st.subheader(\"‚òÅÔ∏è WordCloud del Resumen\")\n",
    "            texto_resumen = \" \".join(palabras_clave)\n",
    "            wc = WordCloud(background_color='white', \n",
    "                           width=800, \n",
    "                           height=400\n",
    "                          ).generate(texto_resumen)\n",
    "\n",
    "            fig, ax = plt.subplots(figsize=(10, 5))\n",
    "            ax.imshow(wc, interpolation='bilinear')\n",
    "            ax.axis(\"off\")\n",
    "            st.pyplot(fig)\n",
    "\n",
    "    else:\n",
    "        st.error(\"‚ùå Por favor ingresa un texto antes de generar el resumen.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e499062-bc14-4b02-a64d-9296388da0da",
   "metadata": {},
   "source": [
    "### <span style=\"color:orange\">visualizador_modelo_25.py</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89bf9b4-081c-4a1f-9f44-434e6a9003f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextlib import redirect_stdout\n",
    "import pydot\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import io\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "st.set_page_config(page_title=\"Resumen de Noticias\", layout=\"wide\")\n",
    "\n",
    "from pages.entrenamiento_modelo_25 import entrenamiento\n",
    "from utils.utils import mostrar_firma_sidebar\n",
    "\n",
    "st.title(\"Visualizaci√≥n del Modelo BiLSTM para Resumen de Textos\")\n",
    "\n",
    "def sidebar():\n",
    "    with st.sidebar:\n",
    "        st.header(\"üß± Arquitectura del modelo\")\n",
    "        st.markdown('---')        \n",
    "        st.page_link('app_resumen_25.py', label='**üè† P√°gina Principal**')\n",
    "        st.page_link('pages/entrenamiento_modelo_25.py', label='**üöÄ Reentrenamiento**')\n",
    "        st.page_link('pages/resumir_texto_manual_25.py', label='**üìù Tu resumen**')\n",
    "\n",
    "sidebar()\n",
    "\n",
    "def graficas(metricas):\n",
    "    st.header(\"Gr√°fica de P√©rdida\")\n",
    "    fig1, ax1 = plt.subplots()\n",
    "    ax1.plot(metricas['loss'], label='Entrenamiento')\n",
    "    ax1.plot(metricas['val_loss'], label='Validaci√≥n')\n",
    "    ax1.set_xlabel(\"√âpocas\")\n",
    "    ax1.set_ylabel(\"P√©rdida\")\n",
    "    ax1.set_title(\"Historial de P√©rdida\")\n",
    "    ax1.legend()\n",
    "    st.pyplot(fig1)\n",
    "\n",
    "    st.header(\"Gr√°fica de Precisi√≥n\")\n",
    "    fig2, ax2 = plt.subplots()\n",
    "    ax2.plot(metricas['accuracy'], label='Entrenamiento')\n",
    "    ax2.plot(metricas['val_accuracy'], label='Validaci√≥n')\n",
    "    ax2.set_xlabel(\"√âpocas\")\n",
    "    ax2.set_ylabel(\"Precisi√≥n\")\n",
    "    ax2.set_title(\"Historial de Precisi√≥n\")\n",
    "    ax2.legend()\n",
    "    st.pyplot(fig2)\n",
    "\n",
    "\n",
    "\n",
    "# === Mostrar Resumen del Modelo ===\n",
    "def mostrar_resumen_modelo(modelo):\n",
    "    st.subheader(\"üìã Resumen del Modelo\")\n",
    "    summary_buffer = io.StringIO()\n",
    "    with redirect_stdout(summary_buffer):\n",
    "        modelo.summary()\n",
    "    st.code(summary_buffer.getvalue(), language='text')\n",
    "\n",
    "\n",
    "# === Generar archivo DOT personalizado ===\n",
    "def generar_dot_con_tablas(model, output_path):\n",
    "    layer_colors = {\n",
    "        \"Embedding\": \"#dcedc8\",\n",
    "        \"Conv1D\": \"#ffccbc\",\n",
    "        \"GlobalMaxPooling1D\": \"#ffe082\",\n",
    "        \"Dense\": \"#bbdefb\",\n",
    "        \"InputLayer\": \"#f0f0f0\"\n",
    "    }\n",
    "\n",
    "    def get_shape_safe(tensor):\n",
    "        try:\n",
    "            return str(tensor.shape)\n",
    "        except:\n",
    "            return \"?\"\n",
    "\n",
    "    with open(output_path, \"w\") as f:\n",
    "        f.write(\"digraph G {\\n\")\n",
    "        f.write(\"    rankdir=TB;\\n\")\n",
    "        f.write(\"    concentrate=true;\\n\")\n",
    "        f.write(\"    dpi=200;\\n\")\n",
    "        f.write(\"    splines=ortho;\\n\")\n",
    "        f.write(\"    node [shape=plaintext fontname=Helvetica];\\n\\n\")\n",
    "\n",
    "        for i, layer in enumerate(model.layers):\n",
    "            name = layer.name\n",
    "            tipo = layer.__class__.__name__\n",
    "            node_id = f\"layer_{i}\"\n",
    "\n",
    "            try:\n",
    "                input_shape = str(layer.input_shape)\n",
    "            except:\n",
    "                input_shape = get_shape_safe(layer.input)\\\n",
    "                if hasattr(layer, \"input\") else \"?\"\n",
    "\n",
    "            try:\n",
    "                output_shape = str(layer.output_shape)\n",
    "            except:\n",
    "                output_shape = get_shape_safe(layer.output)\\\n",
    "                if hasattr(layer, \"output\") else \"?\"\n",
    "\n",
    "            color = layer_colors.get(tipo, \"#eeeeee\")\n",
    "\n",
    "            label = f\"\"\"<\n",
    "            <TABLE BORDER=\"0\" CELLBORDER=\"1\" CELLSPACING=\"0\"\\\n",
    "            CELLPADDING=\"6\" BGCOLOR=\"{color}\">\n",
    "          <TR><TD COLSPAN=\"2\"><B>{name}</B> ({tipo})</TD></TR>\n",
    "          <TR><TD><FONT POINT-SIZE=\"10\">Input</FONT></TD>\n",
    "          <TD><FONT POINT-SIZE=\"10\">{input_shape}</FONT></TD></TR>\n",
    "          <TR><TD><FONT POINT-SIZE=\"10\">Output</FONT></TD>\n",
    "          <TD><FONT POINT-SIZE=\"10\">{output_shape}</FONT></TD></TR>\n",
    "        </TABLE>>\"\"\"\n",
    "            f.write(f'    {node_id} [label={label}];\\n')\n",
    "\n",
    "        for i in range(1, len(model.layers)):\n",
    "            f.write(f'    layer_{i-1} -> layer_{i};\\n')\n",
    "\n",
    "        f.write(\"}\\n\")\n",
    "\n",
    "\n",
    "# === Mostrar Visualizaci√≥n de la Arquitectura ===\n",
    "def mostrar_arquitectura(modelo, dot_output_path, png_output_path):\n",
    "    st.subheader(\"üï∏Ô∏è Arquitectura Visual\")\n",
    "\n",
    "    if not os.path.exists(png_output_path):\n",
    "        try:\n",
    "            generar_dot_con_tablas(modelo, dot_output_path)\n",
    "            (graph,) = pydot.graph_from_dot_file(dot_output_path)\n",
    "            graph.write_png(png_output_path)\n",
    "        except Exception as e:\n",
    "            st.warning(f\"‚ö†Ô∏è No se pudo generar el diagrama: {e}\")\n",
    "\n",
    "    if os.path.exists(png_output_path):\n",
    "        st.image(png_output_path, caption=\"Estructura de la red neuronal\",\n",
    "                 use_column_width=True\n",
    "                )\n",
    "\n",
    "        with open(png_output_path, \"rb\") as file:\n",
    "            st.download_button(\n",
    "                label=\"üíæ Guardar imagen del diagrama\",\n",
    "                data=file,\n",
    "                file_name=\"modelo_arquitectura.png\",\n",
    "                mime=\"image/png\"\n",
    "            )\n",
    "\n",
    "def cargar_modelo(ruta):\n",
    "    # Cargar el modelo\n",
    "    try:\n",
    "        model = load_model(\"models/modelo_resumen_bilstm_25.keras\")\n",
    "        return model\n",
    "    except Exception as e:\n",
    "        st.error(f\"Error al cargar el modelo: {e}\")\n",
    "        st.stop()\n",
    "\n",
    "\n",
    "# === Interfaz Principal ===\n",
    "def main():\n",
    "    # Cargar el historial\n",
    "    if os.path.exists(\"data/metricas_entrenamiento_25.csv\"):\n",
    "        metricas = pd.read_csv(\"data/metricas_entrenamiento_25.csv\")\n",
    "        graficas(metricas)\n",
    "    else:\n",
    "        st.error(\"No se encontr√≥ el archivo 'data/metricas_entrenamiento_25.csv'\")\n",
    "        st.stop()\n",
    "    modelo = cargar_modelo(\"models/modelo_resumen_bilstm_25.keras\")\n",
    "    mostrar_resumen_modelo(modelo)\n",
    "    mostrar_arquitectura(modelo,\n",
    "                         \"images/modelo_coloreado.dot\", \n",
    "                         \"images/modelo_coloreado.png\"\n",
    "                        )\n",
    "\n",
    "# === Lanzar App ===\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "    mostrar_firma_sidebar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f4b718-9424-4245-abce-f38506635ce8",
   "metadata": {},
   "source": [
    "## utils/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072656c3-3984-4753-9c17-85e596c68842",
   "metadata": {},
   "source": [
    "### <span style=\"color:orange\">utils.py</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c9714b-5631-4a49-9d5e-62267b0d0748",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "\n",
    "# pie de p√°gina\n",
    "def mostrar_firma_sidebar():\n",
    "    st.sidebar.markdown(\"\"\"\n",
    "        <style>\n",
    "            .firma-sidebar {\n",
    "                position: fixed;\n",
    "                bottom: 20px;\n",
    "                left: 13px;\n",
    "                width: 10pts;\n",
    "                padding: 10px 15px;\n",
    "                font-size: 0.8rem;\n",
    "                border-radius: 10px;\n",
    "                background-color: rgba(250, 250, 250, 0.9);\n",
    "                z-index: 9999;\n",
    "                text-align: left;\n",
    "            }\n",
    "\n",
    "            .firma-sidebar a {\n",
    "                text-decoration: none;\n",
    "                color: #333;\n",
    "            }\n",
    "\n",
    "            .firma-sidebar a:hover {\n",
    "                color: #0077b5;\n",
    "            }\n",
    "        </style>\n",
    "\n",
    "        <div class=\"firma-sidebar\">\n",
    "            Desarrollado por <strong>Mg. Luis Felipe Bustamante Narv√°ez</strong><br>\n",
    "            <a href=\"https://github.com/luizbn2\" target=\"_blank\">üêô GitHub</a> ¬∑ \n",
    "            <a href=\"https://www.linkedin.com/in/lfbn2\" target=\"_blank\">üíº LinkedIn</a>\n",
    "        </div>\n",
    "    \"\"\", unsafe_allow_html=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e045ea-b621-4234-8370-8f1edf505dba",
   "metadata": {},
   "source": [
    "## Aplicaci√≥n Principal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a33d78-b8c5-4fe3-b8d8-211fc1a7b5e8",
   "metadata": {},
   "source": [
    "### <span style=\"color:orange\">app_resumen_25.py</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6d81f8-1eb3-4ea5-8e19-1316c13323f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import load_model\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "st.set_page_config(page_title=\"Resumen de Noticias\", layout=\"wide\")\n",
    "\n",
    "#aqu√≠ porque esa p√°gina usa streamlit y el set debe quedar primero.\n",
    "from pages.resumen_modelo_25 import resumir_noticia\n",
    "from utils.utils import mostrar_firma_sidebar\n",
    "\n",
    "st.title(\"üß† Generador de Res√∫menes con BiLSTM\")\n",
    "\n",
    "# Cargar modelo y m√©tricas\n",
    "modelo = load_model(\"models/modelo_resumen_bilstm_25.keras\")\n",
    "\n",
    "# Cargar tokenizer\n",
    "with open(\"models/tokenizer_resumen_25.pkl\", \"rb\") as f:\n",
    "    tokenizer = pickle.load(f)\n",
    "\n",
    "# Cargar dataset\n",
    "df = pd.read_csv(\"data/df_total.csv\", encoding='utf-8')\n",
    " # asumimos que no hay columna t√≠tulo\n",
    "df['titulo'] = df['news'].apply(lambda x: x.split('.')[0][:100]) \n",
    "\n",
    "\n",
    "with st.sidebar:\n",
    "    st.header(\"üîç Selecciona una noticia\")\n",
    "    titulo_seleccionado = st.selectbox(\"T√≠tulos disponibles:\", df['titulo'])\n",
    "    umbral = st.slider(\"Ajustar umbral de relevancia\", \n",
    "                       min_value=0.1, \n",
    "                       max_value=0.9, \n",
    "                       value=0.5, \n",
    "                       step=0.05\n",
    "                      )\n",
    "    max_oraciones = st.slider(\"Limitar n√∫mero de oraciones a procesar\", \n",
    "                              min_value=10, \n",
    "                              max_value=200, \n",
    "                              value=100, \n",
    "                              step=10\n",
    "                             )\n",
    "\n",
    "def sidebar():\n",
    "    with st.sidebar:        \n",
    "        st.header(\"üîç Entrenamiento del modelo\")\n",
    "        st.markdown('---')\n",
    "    \n",
    "        st.subheader(\"üìä M√©tricas del Modelo\")\n",
    "\n",
    "        metrics_path = \"data/metricas_entrenamiento_25.csv\"\n",
    "        if os.path.exists(metrics_path):\n",
    "            metricas_df = pd.read_csv(metrics_path)\n",
    "            #st.info(metricas_df)\n",
    "            #st.line_chart(metricas_df[['loss', 'val_loss']])\n",
    "            st.line_chart(metricas_df[['accuracy', 'val_accuracy']])\n",
    "        else:\n",
    "            st.info(\"No se encontraron m√©tricas guardadas.\")\n",
    "        st.markdown('---')\n",
    "        st.page_link('pages/entrenamiento_modelo_25.py', label='**üöÄ Reentrenamiento**')\n",
    "        st.page_link('pages/visualizar_modelo_25.py', label='**üß± Arquitectura**')\n",
    "        st.page_link('pages/resumir_texto_manual_25.py', label='**üìù Tu resumen**')\n",
    "\n",
    "mostrar_firma_sidebar()\n",
    "\n",
    "# ----------------- Selecci√≥n de noticia -----------------\n",
    "\n",
    "\n",
    "# Obtener la noticia seleccionada\n",
    "noticia = df[df['titulo'] == titulo_seleccionado]['news'].values[0]\n",
    "\n",
    "st.subheader(\"üì∞ Noticia Original\")\n",
    "st.write(noticia)\n",
    "\n",
    "sidebar()\n",
    "\n",
    "# ----------------- Generar resumen -----------------\n",
    "if st.button(\"üìå Generar Resumen\"):\n",
    "    resumen, word = resumir_noticia(noticia, modelo, tokenizer, umbral, max_oraciones)\n",
    "    st.subheader(\"üìù Resumen Generado\")\n",
    "    if resumen:\n",
    "        for i, oracion in enumerate(resumen, 1):\n",
    "            st.markdown(f\"{oracion}\\n\\n\")\n",
    "    else:\n",
    "        st.warning(\"‚ö†Ô∏è No se encontraron oraciones relevantes para este umbral.\")\n",
    "\n",
    "    # ----------------- WordCloud del resumen -----------------\n",
    "    if word:\n",
    "        st.subheader(\"‚òÅÔ∏è WordCloud del Resumen\")\n",
    "        resumen_texto = \" \".join(word)\n",
    "        wc = WordCloud(background_color='white', \n",
    "                       width=800, \n",
    "                       height=400\n",
    "                      ).generate(resumen_texto)\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(10, 5))\n",
    "        ax.imshow(wc, interpolation='bilinear')\n",
    "        ax.axis(\"off\")\n",
    "        st.pyplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2354a0d-a8cc-4371-ab95-e324ba819325",
   "metadata": {},
   "source": [
    "## requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1933a62b-4c26-47de-82aa-9ae0b6dc349c",
   "metadata": {},
   "outputs": [],
   "source": [
    "streamlit==1.32.2\n",
    "numpy==1.26.4\n",
    "pandas==2.1.4\n",
    "matplotlib==3.7.5\n",
    "scikit-learn==1.3.2\n",
    "tensorflow==2.17.1\n",
    "pillow==10.1.0\n",
    "pydot==1.4.2\n",
    "graphviz==0.20.1\n",
    "protobuf==3.20.*\n",
    "setuptools>=68.0.0\n",
    "nltk==3.8.1\n",
    "wordcloud==1.9.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942201c1-a896-416e-b845-b5090f0dd38a",
   "metadata": {},
   "source": [
    "## Conclusiones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f492ac92-e54f-4112-9951-14c70798e37a",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <p>Por medio de Streamlit o Flask, podemos visualizar el despliegue de nuestro generador de res√∫menes, mostrando los gr√°ficos y m√©tricas entregadas en cada entrenamiento y cada prueba. Adem√°s de poder reentrenar el modelo y observar nuevas m√©tricas directamente desde el entorno web. Este proyecto est√° alojado en un servidor gratuito, donde no utilizamos los jupyter notebook, sino archivos .py.        \n",
    "    </p>\n",
    "        <hr/>\n",
    "    <p style=\"text-align: right;\">Mg. Luis Felipe Bustamante Narv√°ez</p>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

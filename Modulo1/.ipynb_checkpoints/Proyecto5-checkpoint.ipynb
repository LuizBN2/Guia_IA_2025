{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3982040-2b54-42fd-9e6c-4ad43c869a18",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <h1 style=\"color: red;\">Anexo 5</h1>\n",
    "    <h3>Proyecto 5: Creación de Words Embedding Nivel 2</h3>\n",
    "    <hr/>\n",
    "    <p style=\"text-align: right;\">Mg. Luis Felipe Bustamante Narváez</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ebc87a-4b94-45dc-9c29-1964ad2163ec",
   "metadata": {},
   "source": [
    "## Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5227bdfa-f74d-4d31-ad13-960be962eca4",
   "metadata": {},
   "source": [
    "Es un modelo que se utiliza para aprender representaciones vectoriales de palabras. Estas representaciones pueden capturar muchas propiedades lingüisticas de las palabras, como su significado semántico, gramatical y hasta contextual.\n",
    "\n",
    "Para este segundo ejemplo, usaremos un texto más extenso llamado \"Cien años de soledad\" del escritor colombiano Gabriel García Márquez, que tiene alrededor de 139.318 palabras y 823735 caracteres."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a93808b-0e6d-4cfe-8f0a-a1ca763c8246",
   "metadata": {},
   "source": [
    "## Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bee20013-3b98-41e7-b41f-8f6d4e0e4cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pypdf2 in c:\\users\\luis_\\anaconda3\\envs\\notebook\\lib\\site-packages (3.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install pypdf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8015a81a-229c-4d09-9fd7-e2c628aa69d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from gensim.models import Word2Vec\n",
    "import PyPDF2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e4ad60-864b-4a7c-ba7d-2c089e90e021",
   "metadata": {},
   "source": [
    "## Cargamos el documento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51ac423b-8f6c-466a-895e-7f2325d61b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraer_texto_desde_pdf(ruta_archivo):\n",
    "    with open(ruta_archivo, 'rb') as archivo:\n",
    "        lector = PyPDF2.PdfReader(archivo)\n",
    "        texto = ''\n",
    "        for pagina in range(len(lector.pages)):\n",
    "            texto += lector.pages[pagina].extract_text()\n",
    "        return texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ff8f457-ef3b-451a-b724-6bbcd6c89dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "documento = extraer_texto_desde_pdf('Entrenamiento_Word2Vec/cien_anos_de_soledad.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f131a202-da0f-4856-8cd7-2fa79743ae47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "823735"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documento)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4873080-2e17-4abb-9dbd-2ed569809ba0",
   "metadata": {},
   "source": [
    "## Procesamiento de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60e5886-b82d-42f0-a1d4-9fb982875dc5",
   "metadata": {},
   "source": [
    "El objetivo del procesamiento es convertir el documento en una lista de frases, y cada frase en una lista de palabras, eliminando signos de puntuación y convirtiendo todo a minúsculas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32cb8d0f-e795-4cb5-bb1f-5ab47fceca6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8854"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dividimos el documento en frases usando la coma como separador\n",
    "frases = documento.split(',')\n",
    "len(frases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea9c0adc-728e-4c2b-878d-39de63dabc97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' las huestes de su padre tenían un aspecto de náufragos sin escapatoria'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mostramos un ejemplo\n",
    "frases[500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d330c2c-7dea-4d11-83a4-4b95f4204c0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' sino porque lo único que me faltó fue darte de mamar.» Aureliano escapaba al alba y regresaba a la madrugada siguiente'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mostramos un ejemplo\n",
    "frases[3000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7c06bf6-d070-49db-99c9-2f18003ab90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpiamos las frases\n",
    "frases_limpias = []\n",
    "for frase in frases:\n",
    "    #Eliminamos la puntuación y dividimos por espacios\n",
    "    tokens = frase.translate(str.maketrans('','',string.punctuation)).split()\n",
    "    #print(tokens)  #para mostrar qué ha hecho hasta aquí\n",
    "    #Convertimos a minúsculas\n",
    "    tokens = [word.lower() for word in tokens]\n",
    "    #print(tokens)  #para mostrar qué ha hecho hasta aquí\n",
    "    if tokens:\n",
    "        frases_limpias.append(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "94f86ca3-a3cb-4c0d-9a78-0f4e2d28a3d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['las',\n",
       " 'huestes',\n",
       " 'de',\n",
       " 'su',\n",
       " 'padre',\n",
       " 'tenían',\n",
       " 'un',\n",
       " 'aspecto',\n",
       " 'de',\n",
       " 'náufragos',\n",
       " 'sin',\n",
       " 'escapatoria']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mostramos los resultados\n",
    "frases_limpias[500]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9ff463-a2bb-43e5-a3f0-dee84ce5caad",
   "metadata": {},
   "source": [
    "## Entrenamiento del modelo Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ba4a159-f20d-4ef1-b95a-ef2d220f50af",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(sentences=frases_limpias,\n",
    "                vector_size=500,\n",
    "                window=5,\n",
    "                min_count=1,\n",
    "                workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0acff46e-5c0b-44a7-a55f-713993a934de",
   "metadata": {},
   "source": [
    "### Explicación:\n",
    "\n",
    "- sentences: Es la lista de palabras que vamos a vectorizar\n",
    "- vector_size: Es el tamaño de dimensiones que le daremos al vector\n",
    "- window: Son la cantidad de palabras por encima y por debajo que le darán contexto\n",
    "- min_count: La aparición mínima de una palabra para tenerla en cuenta en el entrenamiento\n",
    "- workers: Cantidad de núcleo de procesador que vamos a invertir en el entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd5bae1-0e34-4f02-ae04-724e6c268e02",
   "metadata": {},
   "source": [
    "## Pruebas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae88f78c-5d7f-4b2a-97d5-74a48bea910e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificamos el vector para alguna palabra\n",
    "vector = model.wv['padre']\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a6b074fc-b590-41da-8a86-1ee061d98dd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('segundo', 0.9980278611183167),\n",
       " ('josé', 0.9935610890388489),\n",
       " ('buendia', 0.9925903081893921),\n",
       " ('tío', 0.9853704571723938),\n",
       " ('aureliano', 0.9842246770858765),\n",
       " ('promovió', 0.9841890335083008),\n",
       " ('pequeño', 0.9830081462860107),\n",
       " ('participó', 0.9812502264976501),\n",
       " ('informaciones', 0.9800763726234436),\n",
       " ('arcadio', 0.9795325398445129)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mostramos las palabras cercanas\n",
    "palabras_cercanas = model.wv.most_similar('buendía', topn=10)\n",
    "palabras_cercanas\n",
    "# Es probable que la similitud falle por tener tan pocas palabras en el texto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660889ed-38eb-42bb-9d0a-b5e459ee345f",
   "metadata": {},
   "source": [
    "## Guardar modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2dfc0fc7-e106-4b65-87c7-10c8977b6726",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('Entrenamiento_Word2Vec/cien_anos_de_soledad.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8c6e49-42d0-441f-b02b-2f30d32adb76",
   "metadata": {},
   "source": [
    "## Cargar el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3b044d59-a128-4709-8673-638a318bd505",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_cargado = Word2Vec.load('Entrenamiento_Word2Vec/cien_anos_de_soledad.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6cd3986e-bb0a-4a9b-af82-3ea5b31ef893",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('segundo', 0.9980278611183167),\n",
       " ('josé', 0.9935610890388489),\n",
       " ('buendia', 0.9925903081893921),\n",
       " ('tío', 0.9853704571723938),\n",
       " ('aureliano', 0.9842246770858765),\n",
       " ('promovió', 0.9841890335083008),\n",
       " ('pequeño', 0.9830081462860107),\n",
       " ('participó', 0.9812502264976501),\n",
       " ('informaciones', 0.9800763726234436),\n",
       " ('arcadio', 0.9795325398445129)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Probamos con el modelo caragado\n",
    "palabras_cercanas2 = modelo_cargado.wv.most_similar('buendía', topn=10)\n",
    "palabras_cercanas2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784098f3-2751-45de-b67c-7302d613321a",
   "metadata": {},
   "source": [
    "## Guardar Embedido\n",
    "\n",
    "Existen dos maneras, usando .txt sin binarios, y usando .bin con binarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5f78ea55-cf0d-4395-9650-32a0a2ad4367",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.save_word2vec_format('Entrenamiento_Word2Vec/cien_anos_de_soledad_emb.txt', binary=False)\n",
    "model.wv.save_word2vec_format('Entrenamiento_Word2Vec/cien_anos_de_soledad_emb.bin', binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59664b52-f853-4557-b4e0-7298c05f29f5",
   "metadata": {},
   "source": [
    "## Cargar Embedidos\n",
    "\n",
    "Si se carga el .txt, se usa sin binarios; si se carga el .bin, se usa con binarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "da56a7c8-519a-4505-a295-5420311b8720",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "embedding_cargado_txt = KeyedVectors.load_word2vec_format(\n",
    "    'Entrenamiento_Word2Vec/cien_anos_de_soledad_emb.txt', binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ac5741aa-c0da-4136-b34b-aeee639b7b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_cargado_bin = KeyedVectors.load_word2vec_format(\n",
    "    'Entrenamiento_Word2Vec/cien_anos_de_soledad_emb.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a4018364-c596-4092-82a1-da7a9fe6dd0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.keyedvectors.KeyedVectors at 0x1116c4d67b0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Probamos\n",
    "embedding_cargado_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fbe8212d-477d-4f87-8268-6dbebea6d77a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.keyedvectors.KeyedVectors at 0x1116c43a390>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Probamos\n",
    "embedding_cargado_bin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11664fde-dba1-4625-8679-d08dad7142ad",
   "metadata": {},
   "source": [
    "## Analogías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a646f171-87b7-4874-9508-73cbaa5410ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analogics(v1, v2, v3):\n",
    "    simil = embedding_cargado_bin.most_similar(positive=[v1,v3], \n",
    "                                               negative=[v2]\n",
    "                                              )\n",
    "    print(f'{v1} es a {v2}, como {simil[0][0]} es a {v3}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2fee7c13-25ae-49b9-956b-f443568103cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aureliano es a buendía, como luz es a iguarán\n"
     ]
    }
   ],
   "source": [
    "analogics('aureliano', 'buendía', 'iguarán')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c4553b-f65a-4e08-be28-45069cf58070",
   "metadata": {},
   "source": [
    "## Conclusiones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982275d7-04d8-4f89-8129-df9eb14e6b9c",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <p>El texto Cien años de soledad, tiene 823735 caracteres, lo que implica una base de datos más grande para entrenar un modelo, pero sigue siendo pequeña para un modelo adecuado. De cierta forma, el modelo se ajusta en algunos casos puntuales, pero suele mostrar demasiadas stopwords en las similitudes, que tendríamos que manipular para mejorar la predicción de analogías. Veremos con un paquete de textos más grandes y variados, como se generaría la predicción.</p>\n",
    "    <hr/>\n",
    "    <p style=\"text-align: right;\">Mg. Luis Felipe Bustamante Narváez</p>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

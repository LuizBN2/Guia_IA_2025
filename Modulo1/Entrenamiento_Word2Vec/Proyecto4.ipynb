{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3982040-2b54-42fd-9e6c-4ad43c869a18",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <h1 style=\"color: red;\">Anexo 4</h1>\n",
    "    <h3>Proyecto 4: Creación de Words Embedding Nivel 1</h3>\n",
    "    <hr/>\n",
    "    <p style=\"text-align: right;\">Mg. Luis Felipe Bustamante Narváez</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ebc87a-4b94-45dc-9c29-1964ad2163ec",
   "metadata": {},
   "source": [
    "## Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5227bdfa-f74d-4d31-ad13-960be962eca4",
   "metadata": {},
   "source": [
    "Es un modelo que se utiliza para aprender representaciones vectoriales de palabras. Estas representaciones pueden capturar muchas propiedades lingüisticas de las palabras, como su significado semántico, gramatical y hasta contextual.\n",
    "\n",
    "Para este primer ejemplo, usaremos un texto corto llamado mundiales que tiene alrededor de 50.000 caracteres."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a93808b-0e6d-4cfe-8f0a-a1ca763c8246",
   "metadata": {},
   "source": [
    "## Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee20013-3b98-41e7-b41f-8f6d4e0e4cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pypdf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8015a81a-229c-4d09-9fd7-e2c628aa69d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from gensim.models import Word2Vec\n",
    "import PyPDF2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e4ad60-864b-4a7c-ba7d-2c089e90e021",
   "metadata": {},
   "source": [
    "## Cargamos el documento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51ac423b-8f6c-466a-895e-7f2325d61b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Entrenamiento_Word2Vec/mundiales.txt',\n",
    "         'r', encoding='utf-8') as file:\n",
    "    documento = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff8f457-ef3b-451a-b724-6bbcd6c89dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "documento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f131a202-da0f-4856-8cd7-2fa79743ae47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48155"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documento)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4873080-2e17-4abb-9dbd-2ed569809ba0",
   "metadata": {},
   "source": [
    "## Procesamiento de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60e5886-b82d-42f0-a1d4-9fb982875dc5",
   "metadata": {},
   "source": [
    "El objetivo del procesamiento es convertir el documento en una lista de frases, y cada frase en una lista de palabras, eliminando signos de puntuación y convirtiendo todo a minúsculas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "32cb8d0f-e795-4cb5-bb1f-5ab47fceca6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "533"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dividimos el documento en frases usando la coma como separador\n",
    "frases = documento.split(',')\n",
    "len(frases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ea9c0adc-728e-4c2b-878d-39de63dabc97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Capítulo 1: Historia del Mundial de Fútbol\\nLos primeros pasos del Mundial\\nLa historia del Mundial de Fútbol se remonta a principios del siglo XX'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mostramos un ejemplo\n",
    "frases[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3d330c2c-7dea-4d11-83a4-4b95f4204c0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' **Adidas**'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mostramos un ejemplo\n",
    "frases[500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b7c06bf6-d070-49db-99c9-2f18003ab90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpiamos las frases\n",
    "frases_limpias = []\n",
    "for frase in frases:\n",
    "    #Eliminamos la puntuación y dividimos por espacios\n",
    "    tokens = frase.translate(str.maketrans('','',string.punctuation)).split()\n",
    "    #print(tokens)  #para mostrar qué ha hecho hasta aquí\n",
    "    #Convertimos a minúsculas\n",
    "    tokens = [word.lower() for word in tokens]\n",
    "    #print(tokens)  #para mostrar qué ha hecho hasta aquí\n",
    "    if tokens:\n",
    "        frases_limpias.append(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "94f86ca3-a3cb-4c0d-9a78-0f4e2d28a3d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['adidas']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mostramos los resultados\n",
    "frases_limpias[500]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9ff463-a2bb-43e5-a3f0-dee84ce5caad",
   "metadata": {},
   "source": [
    "## Entrenamiento del modelo Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0ba4a159-f20d-4ef1-b95a-ef2d220f50af",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(sentences=frases_limpias,\n",
    "                vector_size=500,\n",
    "                window=5,\n",
    "                min_count=1,\n",
    "                workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0acff46e-5c0b-44a7-a55f-713993a934de",
   "metadata": {},
   "source": [
    "### Explicación:\n",
    "\n",
    "- sentences: Es la lista de palabras que vamos a vectorizar\n",
    "- vector_size: Es el tamaño de dimensiones que le daremos al vector\n",
    "- window: Son la cantidad de palabras por encima y por debajo que le darán contexto\n",
    "- min_count: La aparición mínima de una palabra para tenerla en cuenta en el entrenamiento\n",
    "- workers: Cantidad de núcleo de procesador que vamos a invertir en el entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd5bae1-0e34-4f02-ae04-724e6c268e02",
   "metadata": {},
   "source": [
    "## Pruebas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae88f78c-5d7f-4b2a-97d5-74a48bea910e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificamos el vector para alguna palabra\n",
    "vector = model.wv['mundial']\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a6b074fc-b590-41da-8a86-1ee061d98dd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('historia', 0.9089663624763489),\n",
       " ('su', 0.9083009362220764),\n",
       " ('con', 0.9079578518867493),\n",
       " ('y', 0.9078695774078369),\n",
       " ('brasil', 0.9078560471534729),\n",
       " ('en', 0.9078254699707031),\n",
       " ('más', 0.9077353477478027),\n",
       " ('del', 0.9077184200286865),\n",
       " ('francia', 0.9076839685440063),\n",
       " ('juego', 0.9075537919998169)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mostramos las palabras cercanas\n",
    "palabras_cercanas = model.wv.most_similar('jugador', topn=10)\n",
    "palabras_cercanas\n",
    "# Es probable que la similitud falle por tener tan pocas palabras en el texto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660889ed-38eb-42bb-9d0a-b5e459ee345f",
   "metadata": {},
   "source": [
    "## Guardar modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2dfc0fc7-e106-4b65-87c7-10c8977b6726",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('Entrenamiento_Word2Vec/mundiales.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8c6e49-42d0-441f-b02b-2f30d32adb76",
   "metadata": {},
   "source": [
    "## Cargar el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3b044d59-a128-4709-8673-638a318bd505",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_cargado = Word2Vec.load('Entrenamiento_Word2Vec/mundiales.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6cd3986e-bb0a-4a9b-af82-3ea5b31ef893",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('historia', 0.9089663624763489),\n",
       " ('su', 0.9083009362220764),\n",
       " ('con', 0.9079578518867493),\n",
       " ('y', 0.9078695774078369),\n",
       " ('brasil', 0.9078560471534729),\n",
       " ('en', 0.9078254699707031),\n",
       " ('más', 0.9077353477478027),\n",
       " ('del', 0.9077184200286865),\n",
       " ('francia', 0.9076839685440063),\n",
       " ('juego', 0.9075537919998169)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Probamos con el modelo caragado\n",
    "palabras_cercanas2 = modelo_cargado.wv.most_similar('jugador', topn=10)\n",
    "palabras_cercanas2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784098f3-2751-45de-b67c-7302d613321a",
   "metadata": {},
   "source": [
    "## Guardar Embedido\n",
    "\n",
    "Existen dos maneras, usando .txt sin binarios, y usando .bin con binarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5f78ea55-cf0d-4395-9650-32a0a2ad4367",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.save_word2vec_format('Entrenamiento_Word2Vec/munidiales_emb.txt', binary=False)\n",
    "model.wv.save_word2vec_format('Entrenamiento_Word2Vec/munidiales_emb.bin', binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59664b52-f853-4557-b4e0-7298c05f29f5",
   "metadata": {},
   "source": [
    "## Cargar Embedidos\n",
    "\n",
    "Si se carga el .txt, se usa sin binarios; si se carga el .bin, se usa con binarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "da56a7c8-519a-4505-a295-5420311b8720",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "embedding_cargado_txt = KeyedVectors.load_word2vec_format(\n",
    "    'Entrenamiento_Word2Vec/munidiales_emb.txt', binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ac5741aa-c0da-4136-b34b-aeee639b7b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_cargado_bin = KeyedVectors.load_word2vec_format(\n",
    "    'Entrenamiento_Word2Vec/munidiales_emb.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a4018364-c596-4092-82a1-da7a9fe6dd0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.keyedvectors.KeyedVectors at 0x21302849a30>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Probamos\n",
    "embedding_cargado_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fbe8212d-477d-4f87-8268-6dbebea6d77a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.keyedvectors.KeyedVectors at 0x213062ccaa0>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Probamos\n",
    "embedding_cargado_bin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11664fde-dba1-4625-8679-d08dad7142ad",
   "metadata": {},
   "source": [
    "## Analogías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a646f171-87b7-4874-9508-73cbaa5410ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analogics(v1, v2, v3):\n",
    "    simil = embedding_cargado_bin.most_similar(positive=[v1,v3], \n",
    "                                               negative=[v2]\n",
    "                                              )\n",
    "    print(f'{v1} es a {v2}, como {simil[0][0]} es a {v3}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2fee7c13-25ae-49b9-956b-f443568103cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jugador es a fútbol, como brasil es a historia\n"
     ]
    }
   ],
   "source": [
    "analogics('jugador', 'fútbol', 'historia')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c4553b-f65a-4e08-be28-45069cf58070",
   "metadata": {},
   "source": [
    "## Conclusiones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982275d7-04d8-4f89-8129-df9eb14e6b9c",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <p>El texto mundiales tiene cerca de 50.000 caracteres, lo que implica una base de datos pequeña para entrenar un modelo. De cierta forma, el modelo se ajusta en algunos casos puntuales, pero suele mostrar demasiadas stopwords, que tendríamos que manipular para mejorar la predicción de analogías. Veremos con un texto más grande, como se generaría la predicción, por ejemplo el libro \"Cien años de soledad\" de Gabriel García Márquez.</p>\n",
    "    <hr/>\n",
    "    <p style=\"text-align: right;\">Mg. Luis Felipe Bustamante Narváez</p>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

#!/usr/bin/env python
# coding: utf-8

# <div style="text-align: center;">
#     <h1 style="color: green;">Anexo 15</h1>
#     <h3>Proyecto 15: Resumen de textos con Text Rank</h3>
#     <hr/>
#     <p style="text-align: right;">Mg. Luis Felipe Bustamante Narv치ez</p>
# </div>

# En este ejercicio, desarrollaremos un generador de resumen de textos avanzado, utilizando el m칠todo TextRank, el cual permite analizar la similitud de las oraciones y palabras para contextualizar las ideas principales del tecto original.
# 
# Recordemos que el TextRank est치 basado en el PageRank de Google, donde las oraciones o palabras equivalen a las p치ginas web y la similitud entre las oraciones o palabras, representan los enlaces que estas p치ginas tienen con otras p치ginas importantes.

# ## Librer칤as

# In[ ]:


pip install networkx


# In[68]:


import pandas as pd
import numpy as np
import textwrap
import nltk
from nltk.corpus import stopwords
from nltk import word_tokenize
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity 
import textwrap
import networkx as nx
import matplotlib.pyplot as plt


# In[4]:


nltk.download('punkt')
nltk.download('stopwords')


# ## Cargamos los Datos

# In[27]:


path = 'data/df_total.csv'
df = pd.read_csv(path, encoding='utf-8')


# In[28]:


df


# In[29]:


print(df['news'][2][:500])


# In[30]:


# Buscamos una noticia larga para tomar como ejemplo a la hora de hacer el resumen
doc = df['news'].sample()


# In[35]:


print(doc.iloc[0][:500])


# In[36]:


# Obtener el 칤ndice de la noticia para manipulaci칩n de datos
indice = df.index[df['news'] == doc.iloc[0]].tolist()
print(indice)


# In[37]:


# hacemos la prueba con un texto que tiene bastante texto
print(df['news'][257][:100])


# In[38]:


#Buscamos el texto largo que encontramos en una fase de pruebas
doc = df.loc[257, 'news']


# In[41]:


doc[:500]


# ## Procesamiento de Datos

# ### TextWrap

# In[42]:


# Eliminamos las palabras cortadas de las l칤neas
doc2 = textwrap.fill(doc, replace_whitespace=False, fix_sentence_endings=True)


# In[43]:


print(doc2[:500])


# ### Separaci칩n en l칤neas

# In[44]:


# Podemos separar por l칤neas, por puntos o comas, la idea es conservar oraciones
# con ideas claras.
lineas = doc2.split('. ')  #Usamos punto espacio, por las siglas o n칰meros que pueden haber


# In[45]:


len(lineas)


# In[46]:


lineas[22:]


# ### Eliminaci칩n de oraciones vac칤as

# In[47]:


lineas = [item for item in lineas if item.strip()]


# In[48]:


len(lineas)


# In[49]:


lineas[22:]


# ## Vectorizaci칩n

# In[50]:


# Creamos la tokenizaci칩n usando las stopwords descargadas
tokenizar = TfidfVectorizer(stop_words=stopwords.words('spanish'), norm='l1')


# In[51]:


# Creamos la matriz
X = tokenizar.fit_transform(lineas)
X


# In[52]:


# Mostramos la matriz
filas, columnas = X.shape

for i in range(10):  #aqu칤 ponemos las filas, pero al ser muchas el resultado es extenso.
    for j in range(10):
        print(X[i, j], end=' ') # imprime el elemento y un espacio en blanco
    print()  #deja el rengl칩n

# Cada fila va a representar una palabra
# Cada columna va a representar cada una de las oraciones


# ## Calculamos la similitud

# In[53]:


# Matriz de similitud
S = cosine_similarity(X)


# In[54]:


S.shape


# In[55]:


# Muestra de similitudes, por ejemplo la oraci칩n 0, tiene similitud de 0.1248 con la
# oraci칩n 6.
S[:1]


# ## Normalizaci칩n

# In[56]:


S = S / S.sum(axis=1, keepdims=True)


# In[57]:


S[:1]


# In[58]:


# Probamos
S[0].sum()


# ## Suavizado (Markov)

# In[59]:


# Matriz de transici칩n uniforme
U = np.ones_like(S)


# In[60]:


U[:1]


# In[61]:


U.shape


# ### Normalizamos la matriz de transici칩n

# In[62]:


U = U / len(U)


# In[63]:


U[:1]


# ### Matriz de similitud suavizada

# In[64]:


factor = 0.1  #valor peque침o para omitir ceros
S_s = (1 - factor)*S + factor*U


# In[65]:


S_s[:1]


# #### Explicaci칩n
# 
# La matriz original contiene valores 0.0 con los cuales es imposible calcular promedios cuando toda una fila tenga estos valores, lo que generar치 errores de ejecuci칩n o desbordamientos en los resultados. En este caso, usaremos el suavizado de Laplace de Markov, agregando un porcentaje m칤nimo de selecci칩n de los datos con la matriz de transici칩n normalizada, luego aplicamos la f칩rmula S_s = (1 - factor)*S + factor*U que utiliza un factor peque침o que dividir치 los resultados para este caso en un 90% del total, para usar el 10% restante que modifica los ceros posibles encontrados en cada posici칩n de la matriz.

# ## Grafo
# 
# Debemos crearlo por aparte

# In[70]:


# Creamos el grafo
G = nx.from_numpy_array(S_s)
scores_G = nx.pagerank(G)


# In[87]:


# Visualizamos el grafo
plt.figure(figsize=(10,6))
pos = nx.spring_layout(G, seed=42)

# Dibujamos los nodos con tama침o proporcional al score_G
nx.draw_networkx_nodes(G, pos,
                       node_size=[1000 * scores_G[i] for i in G.nodes()],
                       node_color='green',
                       alpha=0.8)

# Dibujar aristas con pesos
edges = G.edges(data=True)
nx.draw_networkx_edges(G, pos,
                       width=[5 * d['weight'] for (_, _, d) in edges],
                       alpha=0.7,
                       edge_color='fuchsia')

# Etiquetas: mostrar la primera parte de cada oraci칩n
labels = {i: f'Oraci칩n {i+1}' for i in G.nodes()}
nx.draw_networkx_labels(G, pos, labels, font_size=10)

plt.title("Grafo de Similitud entre Oraciones (TextRank)")
plt.axis('off')
plt.tight_layout()
plt.show()


# #### Explicaci칩n
# 
# Se crea un grafo no dirigido usando <span style="color:#e60073; font-weight:bold;">G = nx.from_numpy_array(S)</span>, donde cada nodo representa una oraci칩n y cada arista la similitud entre ellas. Posteriormente, se utiliza el <span style="color:#e60073; font-weight:bold;">scores = nx.pagerank(G)</span> para rankear la importancia de cada oraci칩n, seg칰n como se conecta con otras.
# 
# Se crea la figura del pyplot de acuerdo al tama침o del grafo y con el <span style="color:#e60073; font-weight:bold;">draw_networkx_nodes</span> se dimensionan los nodos al tama침o del ranking. Luego, el <span style="color:#e60073; font-weight:bold;">draw_networkx_edges</span>, crea las aristas que interconectan cada nodo. 
# 
# Finalmente, se crean las etiquetas que aparecer치n en cada nodo, para nuestro caso la palabra <span style="color:#e60073; font-weight:bold;">'Oraci칩n'</span> y el n칰mero del peso de la Matriz de similitud suavizada, para mostrarla a trav칠s del <span style="color:#e60073; font-weight:bold;">plt.show()</span>.
# 

# ## TextRank

# ### Matriz Estacionaria
# 
# Ya tenemos la matriz de transici칩n, que nos indica la probabilidad de pasar de una oraci칩n a otra, ahora, necesitamos saber cu치l es la probabilidad del estado actual en el tiempo, es decir de la oraci칩n que se est치 analizando sin tener en en cuenta hacia qu칠 otra oraci칩n puede ir.

# In[92]:


eigen_values, eigen_vectors = np.linalg.eig(S.T)


# In[93]:


eigen_values


# In[94]:


# Buscamos la posici칩n donde el eigen_values fue 1
pos_eigen = np.where(np.isclose(eigen_values, 1.0))[0]
print(pos_eigen[0])


# In[95]:


# Localizamos el eigen_vector de la posici칩n donde hall칩 el 1.0
eigen_vectors[:,pos_eigen[0]]


# #### Explicaci칩n
# 
# 游늷 1. 쯈u칠 es np.linalg.eig()?
# Es una funci칩n de NumPy (np) que calcula:
# 
# - Los valores propios (eigenvalues): escalares 洧랝
# - Los vectores propios (eigenvectors): vectores 洧녺
# 
# ...de una matriz cuadrada 洧냢, tales que:
# 
#                                         洧냢洧녺=洧랝洧녺
# 
# 游늷 2. 쯈u칠 hace S.T?
# S.T es simplemente la transpuesta de la matriz S.
# Si 洧녡 es una matriz de tama침o 洧녴칑洧녵, entonces 洧녡洧녢 es de tama침o 洧녵칑洧녴.
# 
# Este paso puede ser necesario si, por ejemplo, queremos que la matriz sea cuadrada para aplicar la descomposici칩n (ya que solo matrices cuadradas tienen valores/vectores propios bien definidos).
# 
# 游늻 쯈u칠 significan los eigenvalores y eigenvectores?
# - Eigenvalor 洧랝: Indica cu치nto se estira o encoge un vector propio al aplicarle la transformaci칩n 洧냢.
# - Eigenvector 洧녺: Un vector que no cambia de direcci칩n bajo la transformaci칩n 洧냢, solo cambia su magnitud.
# 

# ### Puntuaci칩n

# In[96]:


scores = eigen_vectors[:,pos_eigen[0]]


# In[97]:


sort_index = np.argsort(-scores)


# In[98]:


# orden de oraciones m치s importantes
sort_index


# ## Resumen

# In[111]:


print('Resumen\n')
cantidad_oraciones = 6
for i in sort_index[:cantidad_oraciones]:
    print("\n".join(textwrap.wrap(f"{scores[i]:.2f}: {lineas[i]}", width=50)))


# ## Conclusiones

# <div style="text-align: center;">
#     <p>La tecnolog칤a del m칠todo TextRank, evidencia un avance significativo en la realizaci칩n de res칰menes. Podemos observar la coherencia del texto y como se comprende f치cilmente la idea principal de la noticia que se tom칩 como ejemplo.
#      </p>
#     <hr/>
#     <p style="text-align: right;">Mg. Luis Felipe Bustamante Narv치ez</p>
# </div>

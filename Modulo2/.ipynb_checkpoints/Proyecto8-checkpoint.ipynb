{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6579886e-550d-49b4-bafe-6c5b68367033",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <h1 style=\"color: blue;\">Anexo 8</h1>\n",
    "    <h3>Proyecto 8: Clasificador de texto</h3>\n",
    "    <hr/>\n",
    "    <p style=\"text-align: right;\">Mg. Luis Felipe Bustamante Narv√°ez</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb93151-8e8d-468b-b133-9ba605d92ca0",
   "metadata": {},
   "source": [
    "En este ejercicio realizaremos un clasificador de texto basado en la forma escritural, sint√°ctica y sem√°ntica de dos escritores latinoamericanos, por un lado al argentino Jorge Luis Borges, y por otro frente al uruguayo Mario Benedetti.\n",
    "\n",
    "<div align=\"center\">\n",
    "    <table>\n",
    "        <tr>\n",
    "            <td align=\"center\">\n",
    "                <img src=\"imagenes/jorge-luis-borges.jpg\" alt=\"Jorge Luis Borges\" width=\"200\"><br>\n",
    "                <strong>Jorge Luis Borges</strong>\n",
    "            </td>\n",
    "            <td width=\"50\"></td>\n",
    "            <td align=\"center\">\n",
    "                <img src=\"imagenes/mario-benedetti.jpg\" alt=\"Mario Benedetti\" width=\"211\"><br>\n",
    "                <strong>Mario Benedetti</strong>\n",
    "            </td>\n",
    "        </tr>\n",
    "    </table>\n",
    "</div>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**üìñ 1. Temas y Filosof√≠a**<br><br>\n",
    "**Borges**: Su poes√≠a es filos√≥fica, abstracta y llena de referencias literarias, mitol√≥gicas y metaf√≠sicas. Le interesaban temas como el tiempo, el infinito, el destino, la identidad y la memoria. Su tono es intelectual y a veces enigm√°tico.  \n",
    "\n",
    "**Benedetti**: Escribe de manera m√°s directa y accesible. Sus temas son el amor, la vida cotidiana, la lucha social, el exilio y la esperanza. Su tono es c√°lido, humano y cercano al lector.  \n",
    "\n",
    "**üñã 2. Lenguaje y Estilo**<br><br>\n",
    "**Borges**: Usa un lenguaje elegante, erudito y con muchas met√°foras complejas. Su poes√≠a es reflexiva, con estructuras cl√°sicas y a veces con formas fijas como sonetos.  \n",
    "\n",
    "**Benedetti**: Usa un lenguaje sencillo, directo y coloquial. Sus poemas parecen conversaciones o pensamientos escritos sin mucha ornamentaci√≥n.  \n",
    "\n",
    "**üîÑ 3. Estructura y Ritmo**<br><br>\n",
    "**Borges**: Tiende a usar estructuras m√°s tradicionales con rima y m√©trica cuidadas, aunque tambi√©n experimenta con versos libres.  \n",
    "\n",
    "**Benedetti**: Prefiere el verso libre y la naturalidad del habla cotidiana, sin preocuparse demasiado por la m√©trica.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe49c44-feaf-4266-8f4d-a68d77bedd7d",
   "metadata": {},
   "source": [
    "## Librer√≠as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb1e5a1-f268-4b24-9ede-de41f197ba79",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c7acbc-88c2-4b49-b7b2-1fc4c485d31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install colorama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2021736c-c91e-445d-8b0a-2672af551d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import PyPDF2\n",
    "from IPython.display import display, HTML\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from colorama import Fore, Back, Style"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66ffad8-f107-4ba7-9330-1a17e04dac55",
   "metadata": {},
   "source": [
    "## Cargamos los documentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f32cd131-efca-48b3-b084-3cfb3e9656d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraer_texto_desde_pdf(ruta_archivo):\n",
    "    with open(ruta_archivo, 'rb') as archivo:\n",
    "        lector = PyPDF2.PdfReader(archivo)\n",
    "        texto = ''\n",
    "        for pagina in range(len(lector.pages)):\n",
    "            texto += lector.pages[pagina].extract_text()\n",
    "        return texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a9f4d42-c34f-4a34-a06e-073aa0c94e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "ruta_carpeta = 'textos'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4b75d6-5c31-48e5-9ef8-717182406d92",
   "metadata": {},
   "source": [
    "## Guardamos los textos en una lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9acd905a-6465-43ca-88f7-b45e1ac8852f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[47m\u001b[32m100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "todos_los_textos = []\n",
    "for archivo in tqdm(os.listdir(ruta_carpeta),\n",
    "                   bar_format=f'{Back.WHITE}{Fore.GREEN}{{l_bar}}{{bar}}{Style.RESET_ALL}'):\n",
    "    if archivo.endswith('.pdf'):\n",
    "        ruta_completa = os.path.join(ruta_carpeta, archivo)\n",
    "        try:\n",
    "            documento = extraer_texto_desde_pdf(ruta_completa)\n",
    "            todos_los_textos.append(documento)\n",
    "        except Exception as e:\n",
    "            print(f'Error al procesar {archivo}: {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56808105-4d42-449c-af96-979538943feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "todos_los_textos[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cacfc2e-703e-484d-90de-1bf0e8daa87b",
   "metadata": {},
   "source": [
    "## Procesamiento de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270a6f13-e393-4df3-ad1c-64257e173c7e",
   "metadata": {},
   "source": [
    "Vamos a separar los textos por etiquetas, enumerando los textos de Borgues con la etiqueta 0 y los de Benedetti con la etiqueta 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d209d9bf-d309-4414-9860-d64c4f78ac42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminamos espacios al inicio y al final para evitar problemas con el pdf\n",
    "for texto in todos_los_textos:\n",
    "    archivo = texto.strip()\n",
    "archivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "749ae7ee-ede6-4122-abc5-287836643eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos las listas vac√≠as\n",
    "textos = []\n",
    "etiquetas = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95c2d89-2a0b-4ab9-a4f8-61823c0be175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostramos l√≠nea por l√≠nea los textos de cada escritor\n",
    "#count = 0   #contador de linea para pruebas\n",
    "for etiqueta, texto in enumerate(todos_los_textos):\n",
    "    print(f'\\n--- Texto {etiqueta} ---\\n')\n",
    "    for linea in texto.split(' \\n'):\n",
    "        #count += 1   #contador de l√≠neas para prueba\n",
    "        print(linea)\n",
    "        # Convertimos a min√∫sculas\n",
    "        linea = linea.rstrip().lower()\n",
    "        print(linea)\n",
    "        # Eliminamos signos de puntuaci√≥n\n",
    "        if linea:\n",
    "            linea = linea.translate(str.maketrans('','', string.punctuation))\n",
    "            print(linea)\n",
    "            # Agregamos el texto l√≠mpio y le asignamos su respectiva etiqueta\n",
    "            textos.append(linea)\n",
    "            etiquetas.append(etiqueta)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d53ec6-164a-4707-b05a-57f6c080a6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostramos las listas\n",
    "textos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5756c3f7-f647-4522-9695-84988cb66042",
   "metadata": {},
   "source": [
    "## Entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27be0015-34c9-4da8-b9cd-6d6fbd2e4b7f",
   "metadata": {},
   "source": [
    "X representa la lista de los textos, y Y, representa la lista de las etiquetas, quien ser√≠a nuestra variable a predecir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "35d453e2-620f-43f1-958b-05c8df4e3f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(textos, etiquetas, train_size=0.9, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "40a66a73-2b79-4afd-8bc1-a94834435934",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2222, 247)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mostramos en forma de tupla el tama√±o de cada muestra\n",
    "len(Y_train), len(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "12243915-a1dc-4e18-899d-42a675524676",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('o acaso no la mira', 1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Probamos las muestras de entrenamiento\n",
    "X_train[0], Y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5eb68350-de9f-4dfc-a799-600dfd4be61d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('a inventar la verdad', 1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Probamos las muestras de prueba\n",
    "X_test[0], Y_test[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaeff550-f8b3-47c1-8f1f-1683e348f8af",
   "metadata": {},
   "source": [
    "### Representaci√≥n de palabras desconocidas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf5cc4f-55b4-440c-b81a-2b0bd1e9f360",
   "metadata": {},
   "source": [
    "#### <b>&lt;unk&gt;</b>\n",
    "\n",
    "Es una convenci√≥n utilizada a menudo en <b>NPL</b> para representar palabras desconocidas o fuera del vocabulario. Por ejemplo, <span style=\"color: fuchsia;\">si una palabra no se encontr√≥ en la muestra de entrenamiento, pero aparece en la muestra de prueba, ser√° desconocida, y se requiere agregarle un √≠ndice que diferencie a esta palabra</span>.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4fb63ecc-7f44-421b-aa87-669becb504bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "indice = 1\n",
    "indice_palabras = {'<unk>': 0}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07467305-63e1-4848-a216-669fc845dc72",
   "metadata": {},
   "source": [
    "## Construcci√≥n del diccionario de codificaci√≥n de palabras a √≠ndice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d418e672-fab5-4c02-9a34-80417b1d8cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for texto in X_train:\n",
    "    # Separamos cada palabra\n",
    "    tokens = texto.split()\n",
    "    #print(tokens) # Probamos como se ven los tokens\n",
    "    for token in tokens:\n",
    "        # Buscamos si la palabra no est√° en el √≠ndice para luego agregarla sin repetir\n",
    "        if token not in indice_palabras:\n",
    "            indice_palabras[token] = indice\n",
    "            indice += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a06d4d-4ae1-478a-b227-372a4eea9763",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Mostramos el √≠ndice de palabras - palabras √∫nicas\n",
    "indice_palabras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ad99ce-50ef-4dfc-843e-cbaaf35859b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# tama√±o de palabras √∫nicas\n",
    "indice_palabras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d8af75-e0c0-45af-85ae-ab53956b26ef",
   "metadata": {},
   "source": [
    "### Conversi√≥n del √≠ndice de palabras de String a enteros\n",
    "\n",
    "C√≥mo el entrenamiento no se debe hacer con palabras, creamos una muestra convertida a su valor espec√≠fico en enteros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "95e7aad1-7049-496d-bf88-1800f067d831",
   "metadata": {},
   "outputs": [],
   "source": [
    "# listas para enteros\n",
    "X_train_int = []\n",
    "X_test_int = []\n",
    "# Banderas para ejecutarse una sola vez\n",
    "X_int_train_hecho = False\n",
    "X_int_test_hecho = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4e6f13c5-6674-4a19-8d38-b36644f4df80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversi√≥n de entrenamiento ejecutada con √©xito.\n"
     ]
    }
   ],
   "source": [
    "# Conversi√≥n de los datos de entrenamiento\n",
    "if not X_int_train_hecho:\n",
    "    for texto in X_train:\n",
    "        # dividimos de nuevo en palabras\n",
    "        tokens = texto.split()\n",
    "        # Por cada palabra encontrada la cambia por su valor num√©rico de la clave del diccionario\n",
    "        linea_entero = [ indice_palabras[token] for token in tokens ]\n",
    "        #print(linea_entero)\n",
    "        # Agregamos el nuevo valor a la lista de entrenamiento\n",
    "        X_train_int.append(linea_entero)\n",
    "    X_int_train_hecho = True\n",
    "    print(\"Conversi√≥n de entrenamiento ejecutada con √©xito.\")\n",
    "else:\n",
    "    print(\"La conversi√≥n de entrenamiento ya se hab√≠a ejecutado previamente.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4436c905-0ac5-4386-9231-8e747f4b9a1f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Mostramos la conversi√≥n de entrenamiento\n",
    "X_train_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0f7879ad-550d-4aff-b94e-55e11016f5b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversi√≥n de prueba ejecutada con √©xito.\n"
     ]
    }
   ],
   "source": [
    "# Conversi√≥n de los datos de prueba -- Como puede haber desconocidos, debemos hacer esto:\n",
    "if not X_int_test_hecho:\n",
    "    for texto in X_test:\n",
    "        tokens = texto.split()\n",
    "        linea_entero = [indice_palabras.get(token, 0) for token in tokens] #trae el token o 0\n",
    "        #print(linea_entero)\n",
    "        X_test_int.append(linea_entero)\n",
    "    X_int_test_hecho = True\n",
    "    print(\"Conversi√≥n de prueba ejecutada con √©xito.\")\n",
    "else:\n",
    "    print(\"La conversi√≥n de prueba ya se hab√≠a ejecutado previamente.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9234b319-ccf9-48b0-b769-a93d472c2a1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "247"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mostramos la conversi√≥n de prueba\n",
    "len(X_test_int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ad85f2-e8ce-476b-9801-650935938bb0",
   "metadata": {},
   "source": [
    "## Matriz de Transici√≥n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f862b84-5a7e-4b09-85f2-e4ae4f1e30ec",
   "metadata": {},
   "source": [
    "Como se indic√≥ en la teor√≠a de los procesos de <b style='color:blue'>Markov</b>, se requiere construir una matriz de transici√≥n y los estados iniciales para cada escritor:\n",
    "\n",
    "1. Creamos un vector <b style='color:fuchsia;'>V</b> con el tama√±o total del <b style='color:fuchsia;'>indice_palabras</b>\n",
    "2. Creamos la matriz <b style='color:fuchsia;'>A0</b> para las palabras de <b style='color:blue;'>Borges</b>\n",
    "3. Creamos el vector de probabilidad inicial <b style='color:fuchsia;'>pi0</b> para las palabras de <b style='color:blue;'>Borges</b>\n",
    "4. Creamos la matriz <b style='color:fuchsia;'>A1</b> para las palabras de <b style='color:blue;'>Benedeti</b>\n",
    "5. Creamos el vector de probabilidad inicial <b style='color:fuchsia;'>pi1</b> para las palabras de <b style='color:blue;'>Benedeti</b>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0b7c512c-de92-407c-b4dd-8fa56526c53a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., ..., 1., 1., 1.])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V = len(indice_palabras)\n",
    "# Creamos las matrices y vectores con 1 para poder hacer el suavizado\n",
    "A0 = np.ones((V, V)) \n",
    "pi0 = np.ones(V)\n",
    "A1 = np.ones((V, V)) \n",
    "pi1 = np.ones(V)\n",
    "#Motramos, por ejemplo\n",
    "pi0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62245f80-8076-4a99-9ac5-54f6f83b4bdd",
   "metadata": {},
   "source": [
    "## Funci√≥n de conteo de palabras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "69cac6ea-ee98-4dcf-a953-fa1437138fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_counts(texto_as_int, A, pi):\n",
    "    #Recorremos los tokens\n",
    "    for tokens in texto_as_int:\n",
    "        #Creamos el posible √∫ltimo elemento como referencia\n",
    "        last_index = None\n",
    "        #Recorremos cada elemento de cada l√≠nea\n",
    "        for index in tokens:\n",
    "            #Nos ubicamos en la primera secuencia\n",
    "            if last_index is None:\n",
    "                # Agregamos el valor inicial\n",
    "                pi[index] +=1\n",
    "            else:\n",
    "                # Agregamos los valores a la matriz\n",
    "                A[last_index, index] += 1\n",
    "            # Asignamos el valor actual al last_index\n",
    "            last_index = index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e71fe10f-aaa3-4810-9100-2d71da5d07e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Llamamos la funci√≥n\n",
    "#Para Borges\n",
    "compute_counts([t for t, y in zip(X_train_int, Y_train) if y == 0], A0, pi0)\n",
    "#Para Benedetti\n",
    "compute_counts([t for t, y in zip(X_train_int, Y_train) if y == 1], A1, pi1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8ab979a6-46e9-4650-a102-5d9c520c8cf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., ..., 1., 1., 1.],\n",
       "       [1., 1., 2., ..., 1., 1., 1.],\n",
       "       [1., 1., 1., ..., 1., 1., 1.],\n",
       "       ...,\n",
       "       [1., 1., 1., ..., 1., 1., 1.],\n",
       "       [1., 1., 1., ..., 1., 1., 1.],\n",
       "       [1., 1., 1., ..., 1., 1., 1.]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Probamos\n",
    "A1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab1b1f0-bb09-4949-be3f-6160d7e610a1",
   "metadata": {},
   "source": [
    "### Explicaci√≥n\n",
    "<b style='color:blue;'>\n",
    "pi0 = array([ 1., 10.,  1., ...,  1.,  1.,  1.])\n",
    "</b>\n",
    "<hr>\n",
    "<b style='color:red;'>\n",
    "pi1 = array([ 1., 14.,  1., ...,  1.,  1.,  1.])\n",
    "</b>\n",
    "<hr>\n",
    "<b style='color:orange;'>\n",
    "A0 = array([[1., 1., 1., ..., 1., 1., 1.],\n",
    "       [1., 1., 1., ..., 1., 1., 1.],\n",
    "       [1., 1., 1., ..., 1., 1., 1.],\n",
    "       ...,\n",
    "       [1., 1., 1., ..., 1., 1., 1.],\n",
    "       [1., 1., 1., ..., 1., 1., 1.],\n",
    "       [1., 1., 1., ..., 1., 1., 1.]])\n",
    "</b>\n",
    "<hr>\n",
    "<b style='color:green;'>\n",
    "A1 =  array([[1., 1., 1., ..., 1., 1., 1.],\n",
    "       [1., 1., 2., ..., 1., 1., 1.],\n",
    "       [1., 1., 1., ..., 1., 1., 1.],\n",
    "       ...,\n",
    "       [1., 1., 1., ..., 1., 1., 1.],\n",
    "       [1., 1., 1., ..., 1., 1., 1.],\n",
    "       [1., 1., 1., ..., 1., 1., 1.]])\n",
    "</b>\n",
    "<hr>\n",
    "En el vector inicial <b style='color:blue;'>pi0</b>, la primera posici√≥n corresponde a los unk, la segunda posici√≥n corresponde a la palabra <b>o</b>, y nos est√° indicando que en los textos de Borges aparece iniciando la l√≠nea 10 veces. Si observamos los textos de Benedetti, <b style='color:red;'>pi1</b> , nos indica que aparece 14 veces comenzando la l√≠nea. De esta manera podemos proceder a encontrar la probabilidad.\n",
    "\n",
    "Con respecto a las matrices de transici√≥n, podemos observar en la matriz de Benedetti, <b style='color:green;'>A1</b>, que en la segunda fila, hubo una transici√≥n de la palabra actual a la siguiente, valores que nos indicar√°n el comportamiento natural de los textos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2808b08-7285-4dee-9ad0-9c55a0f1ea16",
   "metadata": {},
   "source": [
    "## Distribuci√≥n de Probabilidad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04df7911-d325-4319-b9ff-21d3a6ac83a5",
   "metadata": {},
   "source": [
    "<b style='color:red;'>Normalizamos</b>\n",
    "\n",
    "Para observar las probabilidades, se requiere normalizar los vectores y matrices generados en el conteo, para que su valor oscile entre 0 y 1, como debe ser.\n",
    "\n",
    "Esta es una manera emp√≠rica de demostrar las f√≥rmulas mencionadas en la teor√≠a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "616b8388-3a88-4ff5-9496-d8b5a339ae26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conservamos los datos originales A0, A1, pi0 y pi1, creando las variables nomralizadas\n",
    "#Para esto vamos a guardar los datos originales\n",
    "A0_norm = A0.copy()\n",
    "pi0_norm = pi0.copy()\n",
    "A1_norm = A1.copy()\n",
    "pi1_norm = pi1.copy()\n",
    "# Bandera de normalizado\n",
    "normalize = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8da4d8f2-7745-4399-97b7-3dc548815406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalizaci√≥n ejecutada con √©xito.\n"
     ]
    }
   ],
   "source": [
    "# Borges\n",
    "if not normalize:\n",
    "    # Borges\n",
    "    A0_norm /= A0_norm.sum(axis=1, keepdims = True)\n",
    "    pi0_norm /= pi0_norm.sum()\n",
    "    # Benedetti\n",
    "    A1_norm /= A1_norm.sum(axis=1, keepdims = True)\n",
    "    pi1_norm /= pi1_norm.sum()\n",
    "    print(\"Normalizaci√≥n ejecutada con √©xito.\")\n",
    "    normalize = True\n",
    "else:\n",
    "    print(\"Las variables ya fueron normalizadas previamente.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dd8a2012-722a-460f-ba37-e65d51327bf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00023111, 0.00231107, 0.00023111, ..., 0.00023111, 0.00023111,\n",
       "       0.00023111])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Probamos\n",
    "pi0_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "819dd660-a3b8-45a8-be48-84cdf67bc3b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00029472, 0.00029472, 0.00029472, ..., 0.00029472, 0.00029472,\n",
       "        0.00029472],\n",
       "       [0.00029155, 0.00029155, 0.00029155, ..., 0.00029155, 0.00029155,\n",
       "        0.00029155],\n",
       "       [0.00029455, 0.00029455, 0.00029455, ..., 0.00029455, 0.00029455,\n",
       "        0.00029455],\n",
       "       ...,\n",
       "       [0.00029472, 0.00029472, 0.00029472, ..., 0.00029472, 0.00029472,\n",
       "        0.00029472],\n",
       "       [0.00029472, 0.00029472, 0.00029472, ..., 0.00029472, 0.00029472,\n",
       "        0.00029472],\n",
       "       [0.00029464, 0.00029464, 0.00029464, ..., 0.00029464, 0.00029464,\n",
       "        0.00029464]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A0_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29616325-3592-4b06-be02-a36db33b15fe",
   "metadata": {},
   "source": [
    "### Explicaci√≥n\n",
    "<b style='color:blue;'>\n",
    "pi0_norm = array([0.00023111, 0.00231107, 0.00023111, ..., 0.00023111, 0.00023111,\n",
    "       0.00023111])\n",
    "</b>\n",
    "<hr>\n",
    "\n",
    "<b style='color:red;'>\n",
    "A0_norm = array([[0.00029472, 0.00029472, 0.00029472, ..., 0.00029472, 0.00029472,\n",
    "        0.00029472],\n",
    "       [0.00029155, 0.00029155, 0.00029155, ..., 0.00029155, 0.00029155,\n",
    "        0.00029155],\n",
    "       [0.00029455, 0.00029455, 0.00029455, ..., 0.00029455, 0.00029455,\n",
    "        0.00029455],\n",
    "       ...,\n",
    "       [0.00029472, 0.00029472, 0.00029472, ..., 0.00029472, 0.00029472,\n",
    "        0.00029472],\n",
    "       [0.00029472, 0.00029472, 0.00029472, ..., 0.00029472, 0.00029472,\n",
    "        0.00029472],\n",
    "       [0.00029464, 0.00029464, 0.00029464, ..., 0.00029464, 0.00029464,\n",
    "        0.00029464]])\n",
    "</b>\n",
    "<hr>\n",
    "\n",
    "En el vector inicial <b style='color:blue;'>pi0</b>, observemos que no aparece ning√∫n valor en cero, lo que indica que el m√©todo de suavizar funci√≥n√≥ perfectamente, al igual que en la matriz <b style='color:red;'>A0</b>, lo que permite una <b>distribuci√≥n de probabilidad</b>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337e6b14-607a-4580-b524-f0b5d55cd5b2",
   "metadata": {},
   "source": [
    "## Espacio logar√≠tmico"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a657a5-1604-4ebf-9d89-4bc17c98287d",
   "metadata": {},
   "source": [
    "Como vimos en la teor√≠a, estas probabilidades pueden tener un desbordamiento por debajo, ya que se aproximan a cero, entonces, para evitar errores computacionales, usaremos el espacio logar√≠tmico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5ee648f8-d605-4189-9cab-f7bc55304fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Borges\n",
    "log_A0_norm = np.log(A0_norm)\n",
    "log_pi0_norm = np.log(pi0_norm)\n",
    "#Benedetti\n",
    "log_A1_norm = np.log(A1_norm)\n",
    "log_pi1_norm = np.log(pi1_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e2e47d7a-279f-4502-a84d-eef267f832a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-8.37262974, -6.07004465, -8.37262974, ..., -8.37262974,\n",
       "       -8.37262974, -8.37262974])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Probamos\n",
    "log_pi0_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "14a03a80-89e6-408e-aa2d-910067f367c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-8.12946976, -8.12946976, -8.12946976, ..., -8.12946976,\n",
       "        -8.12946976, -8.12946976],\n",
       "       [-8.14031554, -8.14031554, -8.14031554, ..., -8.14031554,\n",
       "        -8.14031554, -8.14031554],\n",
       "       [-8.13005904, -8.13005904, -8.13005904, ..., -8.13005904,\n",
       "        -8.13005904, -8.13005904],\n",
       "       ...,\n",
       "       [-8.12946976, -8.12946976, -8.12946976, ..., -8.12946976,\n",
       "        -8.12946976, -8.12946976],\n",
       "       [-8.12946976, -8.12946976, -8.12946976, ..., -8.12946976,\n",
       "        -8.12946976, -8.12946976],\n",
       "       [-8.12976445, -8.12976445, -8.12976445, ..., -8.12976445,\n",
       "        -8.12976445, -8.12976445]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Probamos\n",
    "log_A0_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8386538-41b2-4c47-9a3a-1151de85ca0b",
   "metadata": {},
   "source": [
    "## Pre-an√°lisis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87fc4408-dfa3-49df-85f9-c07a50751611",
   "metadata": {},
   "source": [
    "Vamos a revisar diferentes elementos que nos permitan entender mejor lo que desarrollamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "052b63d4-a2d4-4094-8d0c-a6f08b10eef1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "Se encontr√≥ 934 etiquetas de clase 0, <b style='color:fuchsia;'>Borges</b>,<br>\n",
       "Se encontr√≥ 1288 etiquetas de clase 1, <b style='color:skyblue;'>Benedetti</b>,<br>\n",
       "para un total de <b style='color:red;'>2222</b> ejemplos de entrenamiento.\n",
       "<hr>\n",
       "Las probabilidades a priori ser√≠an las siguientes:<br>\n",
       "<table style=\"border: 1px solid black; border-collapse: collapse;\">\n",
       "  <tr>\n",
       "    <td style=\"border: 1px solid black; padding: 5px;\">Borges</td>\n",
       "    <td style=\"border: 1px solid black; padding: 5px;\">0.42034203420342037</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td style=\"border: 1px solid black; padding: 5px;\">Benedetti</td>\n",
       "    <td style=\"border: 1px solid black; padding: 5px;\">0.5796579657965797</td>\n",
       "  </tr>\n",
       "</table>\n",
       "<hr>\n",
       "Como usamos el espacio logar√≠tmico, estas ser√≠an las probabilidades reales de encontrar un texto de la clase 0 o 1:\n",
       "<table style=\"border: 1px solid black; border-collapse: collapse;\">\n",
       "  <tr>\n",
       "    <td style=\"border: 1px solid black; padding: 5px;\">Borges</td>\n",
       "    <td style=\"border: 1px solid black; padding: 5px;\">-0.8666865319707326</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td style=\"border: 1px solid black; padding: 5px;\">Benedetti</td>\n",
       "    <td style=\"border: 1px solid black; padding: 5px;\">-0.5453170635352763</td>\n",
       "  </tr>\n",
       "</table>\n",
       "<hr>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Conteo de etiquetas de clase 0 (Borges) en Y_train\n",
    "count_Y_0 = sum(y == 0 for y in Y_train)\n",
    "# Conteo de etiquetas de clase 1 (Benedetti) en Y_train\n",
    "count_Y_1 = sum(y == 1 for y in Y_train)\n",
    "# Cantidad total de ejemplos de entrenamiento\n",
    "total = len(Y_train)\n",
    "# Probabilidad a priori de la clase 0\n",
    "p0 = count_Y_0 / total\n",
    "# Probabilidad a priori de la clase 1\n",
    "p1 = count_Y_1 / total\n",
    "# Logaritmo de la clase a priori 0\n",
    "log_p0 = np.log(p0)\n",
    "# Logaritmo de la clase a priori 0\n",
    "log_p1 = np.log(p1)\n",
    "\n",
    "display(HTML(f'''\n",
    "Se encontr√≥ {count_Y_0} etiquetas de clase 0, <b style='color:fuchsia;'>Borges</b>,<br>\n",
    "Se encontr√≥ {count_Y_1} etiquetas de clase 1, <b style='color:skyblue;'>Benedetti</b>,<br>\n",
    "para un total de <b style='color:red;'>{total}</b> ejemplos de entrenamiento.\n",
    "<hr>\n",
    "Las probabilidades a priori ser√≠an las siguientes:<br>\n",
    "<table style=\"border: 1px solid black; border-collapse: collapse;\">\n",
    "  <tr>\n",
    "    <td style=\"border: 1px solid black; padding: 5px;\">Borges</td>\n",
    "    <td style=\"border: 1px solid black; padding: 5px;\">{p0}</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td style=\"border: 1px solid black; padding: 5px;\">Benedetti</td>\n",
    "    <td style=\"border: 1px solid black; padding: 5px;\">{p1}</td>\n",
    "  </tr>\n",
    "</table>\n",
    "<hr>\n",
    "Como usamos el espacio logar√≠tmico, estas ser√≠an las probabilidades reales de encontrar un texto de la clase 0 o 1:\n",
    "<table style=\"border: 1px solid black; border-collapse: collapse;\">\n",
    "  <tr>\n",
    "    <td style=\"border: 1px solid black; padding: 5px;\">Borges</td>\n",
    "    <td style=\"border: 1px solid black; padding: 5px;\">{log_p0}</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td style=\"border: 1px solid black; padding: 5px;\">Benedetti</td>\n",
    "    <td style=\"border: 1px solid black; padding: 5px;\">{log_p1}</td>\n",
    "  </tr>\n",
    "</table>\n",
    "<hr>\n",
    "'''))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea682534-7567-4b9b-8e6d-68d361472ae8",
   "metadata": {},
   "source": [
    "## Construcci√≥n del Clasificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "87d11e8e-9ec6-47ff-ba44-8f11519798c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos una clase\n",
    "class Classifier:\n",
    "    # Constructor\n",
    "    def __init__(self, log_As, log_pis, log_apriors):\n",
    "        self.log_As = log_As\n",
    "        self.log_pis = log_pis\n",
    "        self.log_apriors = log_apriors\n",
    "        # n√∫mero de clases\n",
    "        self.k = len(log_apriors)\n",
    "\n",
    "    # M√©todo de verosimilitud\n",
    "    def _compute_log_likelihood(self, input_, class_):\n",
    "        log_A = self.log_As[class_]\n",
    "        log_pi = self.log_pis[class_]\n",
    "        #Repetimos lo hecho en el ejemplos de creaci√≥n de la matriz\n",
    "        last_index = None\n",
    "        log_prob = 0\n",
    "        #Recorremos la entrada del usuario\n",
    "        for index in input_:\n",
    "            if last_index is None:\n",
    "                #Primer token en la secuencia\n",
    "                log_prob += log_pi[index]\n",
    "            else:\n",
    "                #Calculamos la probabilidad de transici√≥n del a palabra anterior a la actual\n",
    "                log_prob += log_A[last_index, index]\n",
    "            #Actualizamos el index para la pr√≥xima iteraci√≥n\n",
    "            last_index = index\n",
    "        return log_prob\n",
    "\n",
    "    # Funci√≥n de predicci√≥n\n",
    "    def predict(self, inputs):\n",
    "        predictions = np.zeros(len(inputs))\n",
    "        for i, input_ in enumerate(inputs):\n",
    "            # Calcula los logaritmos de las probabilidades posteriores para cada clase\n",
    "            posteriors = [self._compute_log_likelihood(input_, c) + self.log_apriors[c] \\\n",
    "                          for c in range(self.k)]\n",
    "            #Elige la clase de mayor probabilidad posterior como la predicci√≥n\n",
    "            pred = np.argmax(posteriors)\n",
    "            predictions[i] = pred\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1714e8-5aea-4b02-a692-257e5b2acadf",
   "metadata": {},
   "source": [
    "### Explicaci√≥n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e469a0-ff36-475c-a7de-4bba1f9145c9",
   "metadata": {},
   "source": [
    "1Ô∏è‚É£ Constructor (__init__)\n",
    "üìå ¬øQu√© par√°metros recibe?\n",
    "\n",
    "log_As: Matrices de probabilidades de transici√≥n entre palabras en logaritmo.\n",
    "log_pis: Probabilidades iniciales de cada palabra en logaritmo.\n",
    "log_apriors: Probabilidades previas (prior) de cada clase en logaritmo.\n",
    "self.k: N√∫mero total de clases.\n",
    "\n",
    "üìå ¬øPor qu√© usa logaritmos?\n",
    "‚úÖ Evita problemas de underflow cuando se multiplican muchas probabilidades peque√±as.\n",
    "‚úÖ Convierte productos en sumas, lo que hace m√°s f√°cil la optimizaci√≥n.\n",
    "\n",
    "2Ô∏è‚É£ M√©todo _compute_log_likelihood (C√°lculo de Verosimilitud)\n",
    "\n",
    "üìå ¬øQu√© hace?\n",
    "\n",
    "Calcula la log-verosimilitud de una secuencia (input_) dada una clase (class_).\n",
    "Usa la probabilidad inicial de la primera palabra (log_pi[index]).\n",
    "Luego, suma las probabilidades de transici√≥n entre palabras (log_A[last_index, index]).\n",
    "Retorna log_prob, que indica qu√© tan probable es la secuencia dada la clase.\n",
    "\n",
    "3Ô∏è‚É£ M√©todo predict (Clasificaci√≥n)\n",
    "\n",
    "üìå ¬øQu√© hace?\n",
    "\n",
    "Inicializa predictions con ceros (un array para almacenar las predicciones).\n",
    "\n",
    "Para cada entrada en inputs:\n",
    "Calcula las log-verosimilitudes para cada clase.\n",
    "Suma la probabilidad previa (prior) log_apriors[c] de cada clase.\n",
    "Elige la clase con mayor probabilidad posterior usando np.argmax().\n",
    "Devuelve predictions, que contiene las clases predichas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c0aa3d-98ea-4461-94c6-56fdb7ef1ab8",
   "metadata": {},
   "source": [
    "## Objeto de la clase Clasifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f2f2741d-badf-4b2e-848c-182bd98141e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos un objeto de la clase Clasifier para llamar los m√©todos del clasificador\n",
    "clf = Classifier([log_A0_norm, log_A1_norm], [log_pi0_norm, log_pi1_norm], [log_p0, log_p1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8162eb3-a755-42e8-bbed-86edad26a3fb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Explicaci√≥n\n",
    "\n",
    "La clase Classifier, recibe 3 par√°metros en su constructor, es decir 3 atributos. En su orden estos atributos son:\n",
    "\n",
    "1Ô∏è‚É£[log_A0_norm, log_A1_norm] que ser√°n los argumentos de log_As\n",
    "\n",
    "2Ô∏è‚É£[log_pi0_norm, log_pi1_norm] que ser√°n los argumentos de log_pis\n",
    "\n",
    "3Ô∏è‚É£[log_p0, log_p1] que ser√°n los argumentos de log_apriors\n",
    "\n",
    "Es decir,\n",
    "\n",
    "1Ô∏è‚É£ Las matrices de transici√≥n normalizadas\n",
    "\n",
    "2Ô∏è‚É£ Los vectores con los valores iniciales o estados iniciales\n",
    "\n",
    "3Ô∏è‚É£ Las probabilidades de cada clase utilizando el espacio logar√≠tmico\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b751cd4-c9eb-4444-944e-4303ce5cbed9",
   "metadata": {},
   "source": [
    "## Predicci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "de3cdde9-4a82-4831-905b-1df318b4defc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuraci Train: 0.9932493249324933\n"
     ]
    }
   ],
   "source": [
    "# Llamamos al m√©todo predict  (Datos de entrenamiento: Aprox 1.0)\n",
    "P_train = clf.predict(X_train_int)\n",
    "# Mostramos la predicci√≥n con la muestra de entrenamiento\n",
    "print(f'Accuraci Train: {np.mean(P_train == Y_train)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6704970d-a7c3-4724-be1a-eef6f724bd27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "247"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "965d4dbb-93c7-47b5-a0c6-0503936eaa71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuraci Test: 0.7530364372469636\n"
     ]
    }
   ],
   "source": [
    "# Llamamos al m√©todo predict (Datos de prueba)\n",
    "P_test = clf.predict(X_test_int)\n",
    "# Mostramos la predicci√≥n con la muestra de prueba\n",
    "print(f'Accuraci Test: {np.mean(P_test == Y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a319531-e01d-453a-b56e-35f58583faa1",
   "metadata": {},
   "source": [
    "## Probamos con textos nuevos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8357ef19-bd43-4149-8d22-d95cce04140b",
   "metadata": {},
   "source": [
    "### üìñ Textos en los estilos de Borges y Benedetti\n",
    "\n",
    "Le solicitamos a ChatGPT4 que nos generara textos con escritura similar a cada uno de nuestros poetas, y esto fue lo que nos entreg√≥.\n",
    "\n",
    "#### **Estilo Borges**\n",
    "<div style=\"color: orange; font-style: italic;\">\n",
    "    En el vasto archivo del tiempo,<br>  \n",
    "    donde las sombras del ayer se funden<br>  \n",
    "    con las visiones inciertas del ma√±ana,<br>  \n",
    "    el hombre camina por un laberinto<br>  \n",
    "    de palabras y azares.</p>\n",
    "    <p>Sabe, aunque lo olvida a menudo,<br>  \n",
    "    que su destino est√° tejido con hilos invisibles,<br>  \n",
    "    urdidos por manos que jam√°s ver√°.</p> \n",
    "    <p>Alguna tarde,<br>  \n",
    "    quiz√° en la penumbra de una biblioteca<br>  \n",
    "    o en la geometr√≠a secreta de un sue√±o,<br>  \n",
    "    descubrir√° que su vida no ha sido sino el eco de otras vidas,<br>  \n",
    "    el reflejo de una historia que ya ha sido escrita<br>  \n",
    "    en un idioma remoto y perfecto.</p>  \n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "#### **Estilo Benedetti**\n",
    "<div style=\"color: brown; font-style: italic;\">\n",
    "    La ciudad despierta con su ritmo de siempre,<br>  \n",
    "    entre murmullos de bocacalles<br>  \n",
    "    y pasos apurados que no saben bien a d√≥nde van.<br>  \n",
    "    <br>  \n",
    "    En un caf√© cualquiera,<br>  \n",
    "    un hombre revuelve su taza con la mirada perdida,<br>  \n",
    "    tal vez recordando un amor que ya no est√°,<br>  \n",
    "    tal vez so√±ando con la ternura que a√∫n no llega.<br>  \n",
    "    <br>  \n",
    "    Afuera, la vida sigue su curso,<br>  \n",
    "    con su cuota justa de olvidos y de esperanzas,<br>  \n",
    "    con sus rutinas que a veces duelen y a veces salvan.<br>  \n",
    "    <br>  \n",
    "    Porque, al final de cuentas,<br>  \n",
    "    lo importante no es cu√°nto nos golpea el tiempo,<br>  \n",
    "    sino con qui√©n elegimos compartirlo.<br>  \n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da8c639-8199-4bb9-9dc2-7a3a52154e15",
   "metadata": {},
   "source": [
    "### Funciones para poner a prueba el nuevo texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4d0737ae-249b-468d-8079-3940e73055e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocesar_texto(texto):\n",
    "    texto = texto.lower().translate(str.maketrans('', '', string.punctuation))\n",
    "    tokens = texto.split()\n",
    "    return tokens\n",
    "\n",
    "def convertir_a_indices(tokens, indice_palabras):\n",
    "    return [indice_palabras.get(token, 0) for token in tokens]  # 0 para <unk>\n",
    "\n",
    "def calcular_probabilidad(tokens_indices, log_pi, log_A):\n",
    "    if not tokens_indices:\n",
    "        return -np.inf  # Evitar errores con texto vac√≠o\n",
    "    log_prob = log_pi[tokens_indices[0]]  # Probabilidad inicial\n",
    "    for i in range(len(tokens_indices) - 1):\n",
    "        log_prob += log_A[tokens_indices[i], tokens_indices[i + 1]]  # Probabilidad de transici√≥n\n",
    "    return log_prob\n",
    "\n",
    "def clasificar_texto(texto, log_pi0_norm, log_A0_norm, log_pi1_norm, log_A1_norm, indice_palabras):\n",
    "    tokens = preprocesar_texto(texto)\n",
    "    tokens_indices = convertir_a_indices(tokens, indice_palabras)\n",
    "    \n",
    "    log_prob_borges = calcular_probabilidad(tokens_indices, log_pi0_norm, log_A0_norm)\n",
    "    log_prob_benedetti = calcular_probabilidad(tokens_indices, log_pi1_norm, log_A1_norm)\n",
    "\n",
    "    #Conversi√≥n de LOG-PROBABILIDADES a PROBABILIDADES\n",
    "    max_log_prob = max(log_prob_borges, log_prob_benedetti)  # Para evitar underflow num√©rico\n",
    "    prob_borges = np.exp(log_prob_borges - max_log_prob)\n",
    "    prob_benedetti = np.exp(log_prob_benedetti - max_log_prob)\n",
    "    total_prob = prob_borges + prob_benedetti\n",
    "    prob_borges /= total_prob  # Normalizamos\n",
    "    prob_benedetti /= total_prob\n",
    "    \n",
    "    print(f\"Probabilidad Borges: {prob_borges:.4f}\")\n",
    "    print(f\"Probabilidad Benedetti: {prob_benedetti:.4f}\")\n",
    "\n",
    "    return \"Borges\" if prob_borges > prob_benedetti else \"Benedetti\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f735c34e-0a1d-438a-9e5a-e8836a6a794d",
   "metadata": {},
   "source": [
    "#### Explicaci√≥n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1538f483-8ed1-47ef-a1c4-f4037435cec5",
   "metadata": {},
   "source": [
    "Este c√≥digo implementa un clasificador de texto que determina si un texto nuevo se asemeja m√°s a un escrito de Borges o de Benedetti. Lo hace utilizando un modelo basado en cadenas de Markov, donde se calculan probabilidades de transici√≥n entre palabras.\n",
    "\n",
    "1Ô∏è‚É£ preprocesar_texto(texto)\n",
    "\n",
    "Objetivo:\n",
    "Convierte el texto en min√∫sculas, elimina signos de puntuaci√≥n y lo divide en palabras (tokens).\n",
    "\n",
    "Proceso:\n",
    "1. texto.lower() ‚Üí Convierte todo el texto a min√∫sculas.\n",
    "2. .translate(str.maketrans('', '', string.punctuation)) ‚Üí Elimina la puntuaci√≥n.\n",
    "3. .split() ‚Üí Divide el texto en palabras, generando una lista de tokens.\n",
    "\n",
    "2Ô∏è‚É£ convertir_a_indices(tokens, indice_palabras)\n",
    "\n",
    "Objetivo:\n",
    "Convierte cada palabra (token) en un √≠ndice num√©rico basado en un diccionario indice_palabras.\n",
    "\n",
    "Proceso:\n",
    "\n",
    "1. Usa indice_palabras.get(token, 0) para obtener el √≠ndice de cada palabra en el diccionario.\n",
    "2. Si la palabra no est√° en el diccionario, se asigna 0 (se usa para <unk>, palabras desconocidas).\n",
    "\n",
    "3Ô∏è‚É£ calcular_probabilidad(tokens_indices, log_pi, log_A)\n",
    "\n",
    "Objetivo:\n",
    "Calcula la log-probabilidad de una secuencia de palabras en base a un modelo de cadenas de Markov.\n",
    "\n",
    "Proceso:\n",
    "\n",
    "1. Si tokens_indices est√° vac√≠o, retorna -np.inf (evita errores).\n",
    "2. Toma la log-probabilidad inicial de la primera palabra: log_pi[tokens_indices[0]].\n",
    "3. Para cada par de palabras consecutivas en la secuencia, suma la log-probabilidad de transici√≥n log_A.\n",
    "\n",
    "4Ô∏è‚É£ clasificar_texto(...)\n",
    "\n",
    "Objetivo:\n",
    "Clasifica un texto como \"Borges\" o \"Benedetti\" en funci√≥n de su probabilidad de generaci√≥n en cada modelo.\n",
    "\n",
    "Proceso:\n",
    "\n",
    "1. Preprocesa el texto ‚Üí Obtiene los tokens.\n",
    "2. Convierte los tokens a √≠ndices ‚Üí Transforma palabras en n√∫meros.\n",
    "3. Calcula log-probabilidades para ambos modelos (Borges y Benedetti).\n",
    "4. Convierte log-probabilidades a probabilidades reales para interpretaci√≥n:\n",
    "    - Se resta el m√°ximo log-probabilidad para evitar problemas num√©ricos (underflow).\n",
    "    - Se aplica np.exp(log_prob - max_log_prob) para convertir log a probabilidad.\n",
    "    - Se normaliza dividiendo entre la suma total.\n",
    "5. Imprime las probabilidades y retorna la clasificaci√≥n."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb9dbf4-7d3a-4f68-a823-ad15d6342429",
   "metadata": {},
   "source": [
    "### Ingreso del nuevo texto - Similar a Borges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a7359b82-f124-4cf1-842b-c0d6de9d5223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilidad Borges: 1.0000\n",
      "Probabilidad Benedetti: 0.0000\n",
      "Clasificaci√≥n: Borges\n"
     ]
    }
   ],
   "source": [
    "texto_prueba = \"\"\"\n",
    "En la vastedad de la memoria,\n",
    "donde los ecos de los d√≠as transcurridos\n",
    "se entrelazan con los espejismos del porvenir,\n",
    "el hombre camina por un laberinto\n",
    "de palabras y azares.\n",
    "\n",
    "Sabe, aunque lo olvida a menudo,\n",
    "que su destino est√° tejido con hilos invisibles,\n",
    "urdidos por manos que jam√°s ver√°.\n",
    "\n",
    "Alguna tarde,\n",
    "quiz√° en la penumbra de una biblioteca\n",
    "o en la geometr√≠a secreta de un sue√±o,\n",
    "descubrir√° que su vida no ha sido sino el eco de otras vidas,\n",
    "el reflejo de una historia que ya ha sido escrita\n",
    "en un idioma remoto y perfecto.\n",
    "\"\"\"\n",
    "resultado = clasificar_texto(texto_prueba, log_pi0_norm, log_A0_norm, log_pi1_norm, log_A1_norm, indice_palabras)\n",
    "print(f\"Clasificaci√≥n: {resultado}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d582e5c4-d53a-4d85-b786-709580a54b44",
   "metadata": {},
   "source": [
    "### Ingreso del nuevo texto - Similar a Benedetti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "05c28781-7be2-4940-8729-74a45702ddac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilidad Borges: 0.0028\n",
      "Probabilidad Benedetti: 0.9972\n",
      "Clasificaci√≥n: Benedetti\n"
     ]
    }
   ],
   "source": [
    "texto_prueba = \"\"\"\n",
    "La ciudad despierta con su ritmo de siempre,\n",
    "entre murmullos de bocacalles\n",
    "y pasos apurados que no saben bien a d√≥nde van.\n",
    "\n",
    "En un caf√© cualquiera,\n",
    "un hombre revuelve su taza con la mirada perdida,\n",
    "tal vez recordando un amor que ya no est√°,\n",
    "tal vez so√±ando con la ternura que a√∫n no llega.\n",
    "\n",
    "Afuera, la vida sigue su curso,\n",
    "con su cuota justa de olvidos y de esperanzas,\n",
    "con sus rutinas que a veces duelen y a veces salvan.\n",
    "\n",
    "Porque, al final de cuentas,\n",
    "lo importante no es cu√°nto nos golpea el tiempo,\n",
    "sino con qui√©n elegimos compartirlo.\n",
    "\"\"\"\n",
    "resultado = clasificar_texto(texto_prueba, log_pi0_norm, log_A0_norm, log_pi1_norm, log_A1_norm, indice_palabras)\n",
    "print(f\"Clasificaci√≥n: {resultado}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2949384c-53f9-49ce-b9fa-4a4a3dc9f10e",
   "metadata": {},
   "source": [
    "## Guardar como .py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b4934732-237d-418e-a929-f398cf45e805",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!jupyter nbconvert --to script Proyecto8.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea651f3-2c0f-410e-af5c-9012f76ed5aa",
   "metadata": {},
   "source": [
    "## Conclusiones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533cbf91-c494-493a-9ce2-33b2edac89da",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <p>Se puede observar como los datos de prueba, permiten clasificar los textos con un 75% de presici√≥n, de tal manera que al poner textos de estos poetas, f√°cilmente podr√° indicar quien lo escribi√≥.</p>\n",
    "    <hr/>\n",
    "    <p style=\"text-align: right;\">Mg. Luis Felipe Bustamante Narv√°ez</p>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

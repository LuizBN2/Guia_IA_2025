{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35f83dd2-2ca9-4372-92b9-720ea0f9b676",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <h1 style=\"color: blue;\">Anexo 10</h1>\n",
    "    <h3>Proyecto 10: Spinning de Texto</h3>\n",
    "    <hr/>\n",
    "    <p style=\"text-align: right;\">Mg. Luis Felipe Bustamante Narváez</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d986c01-b330-404b-8fdc-d2dc310dd8db",
   "metadata": {},
   "source": [
    "## Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "f9a2e963-20b3-4766-860e-4feb5b655e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "import asyncio\n",
    "from tqdm import tqdm\n",
    "from colorama import Fore, Back, Style\n",
    "import os\n",
    "from itertools import islice\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "859f0c18-3eda-4ec0-901c-e390323c1ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\luis_\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Descargamos el conjunto de datos del tokenizador en español\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4e3d89-9194-4762-9776-7e297c2b669b",
   "metadata": {},
   "source": [
    "## Cargamos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "badb138d-00cf-4d52-8e35-7b2b5dab5e4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding utf-8\n"
     ]
    }
   ],
   "source": [
    "# Es común que los archivos vengan codificados con ISO\n",
    "path = 'data/data_larazon_publico_v2.csv'\n",
    "path_utf = 'data/new_data.csv'\n",
    "try:\n",
    "    df = pd.read_csv(path, encoding='utf-8')\n",
    "    print('Encoding utf-8')\n",
    "except Exception:\n",
    "    print('Encoding ISO-8859-1 a utf-8')\n",
    "    df_iso = pd.read_csv(path, encoding='ISO-8859-1')\n",
    "    df_iso.to_csv(path_utf, encoding='utf-8', index=False)\n",
    "    #await asyncio.sleep(3) #Espera 3 seg para abrir el nuevo archivo en espera de ser guardad\n",
    "    df = pd.read_csv(path_utf, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e5b34f16-dd86-430d-856d-4225b792e6bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>indi</th>\n",
       "      <th>cuerpo</th>\n",
       "      <th>titular</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dos semanas después de su puesta de largo y pr...</td>\n",
       "      <td>el submarino s-80 ya flota</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>este viernes, el presidente del gobierno, pedr...</td>\n",
       "      <td>calviño y calvo alaban (sin darse cuenta) la g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>el ministro del interior, fernando grande-marl...</td>\n",
       "      <td>el geo de la policía tendrá una nueva sede en ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>son días muy duros para la familia de olivia y...</td>\n",
       "      <td>la madre de las niñas \"sobran las palabras par...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>sólo quedan 10 presos de eta por recibir los b...</td>\n",
       "      <td>sólo quedan 10 presos de eta por recibir el be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58419</th>\n",
       "      <td>58420</td>\n",
       "      <td>18419</td>\n",
       "      <td>la comisión europea inició este un procedimien...</td>\n",
       "      <td>bruselas abre un expediente a españa por no de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58420</th>\n",
       "      <td>58421</td>\n",
       "      <td>18420</td>\n",
       "      <td>el pleno de la asamblea de madrid ha aprobado ...</td>\n",
       "      <td>aprobado el proyecto de ley para que las mujer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58421</th>\n",
       "      <td>58422</td>\n",
       "      <td>18421</td>\n",
       "      <td>la comisión de investigación parlamentaria del...</td>\n",
       "      <td>la comisión del alvia arranca escuchando a la ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58422</th>\n",
       "      <td>58423</td>\n",
       "      <td>18422</td>\n",
       "      <td>erc y pdecat han calificado este jueves de \"in...</td>\n",
       "      <td>erc y pdecat piden explicaciones a interior po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58423</th>\n",
       "      <td>58424</td>\n",
       "      <td>18423</td>\n",
       "      <td>la junta de portavoces del congreso ha acordad...</td>\n",
       "      <td>el congreso aplaza la primera sesión de contro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>58424 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  ...                                            titular\n",
       "0               0  ...                         el submarino s-80 ya flota\n",
       "1               1  ...  calviño y calvo alaban (sin darse cuenta) la g...\n",
       "2               2  ...  el geo de la policía tendrá una nueva sede en ...\n",
       "3               3  ...  la madre de las niñas \"sobran las palabras par...\n",
       "4               4  ...  sólo quedan 10 presos de eta por recibir el be...\n",
       "...           ...  ...                                                ...\n",
       "58419       58420  ...  bruselas abre un expediente a españa por no de...\n",
       "58420       58421  ...  aprobado el proyecto de ley para que las mujer...\n",
       "58421       58422  ...  la comisión del alvia arranca escuchando a la ...\n",
       "58422       58423  ...  erc y pdecat piden explicaciones a interior po...\n",
       "58423       58424  ...  el congreso aplaza la primera sesión de contro...\n",
       "\n",
       "[58424 rows x 4 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2bc5e58c-d635-4287-b3c6-497e50a4a2b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>indi</th>\n",
       "      <th>cuerpo</th>\n",
       "      <th>titular</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dos semanas después de su puesta de largo y pr...</td>\n",
       "      <td>el submarino s-80 ya flota</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>este viernes, el presidente del gobierno, pedr...</td>\n",
       "      <td>calviño y calvo alaban (sin darse cuenta) la g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>el ministro del interior, fernando grande-marl...</td>\n",
       "      <td>el geo de la policía tendrá una nueva sede en ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>son días muy duros para la familia de olivia y...</td>\n",
       "      <td>la madre de las niñas \"sobran las palabras par...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>sólo quedan 10 presos de eta por recibir los b...</td>\n",
       "      <td>sólo quedan 10 presos de eta por recibir el be...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  ...                                            titular\n",
       "0           0  ...                         el submarino s-80 ya flota\n",
       "1           1  ...  calviño y calvo alaban (sin darse cuenta) la g...\n",
       "2           2  ...  el geo de la policía tendrá una nueva sede en ...\n",
       "3           3  ...  la madre de las niñas \"sobran las palabras par...\n",
       "4           4  ...  sólo quedan 10 presos de eta por recibir el be...\n",
       "\n",
       "[5 rows x 4 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad847a4-1e5b-4368-9a65-0fd7758c77b5",
   "metadata": {},
   "source": [
    "## Creamos la Serie con las noticias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "0166da69-fdb7-4e55-b5cb-5e63e28db78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tomamos solamente la columna abstract para crear una serie\n",
    "textos = df['cuerpo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f20f168b-1ec0-445e-a069-b92f3746a7d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    dos semanas después de su puesta de largo y pr...\n",
       "1    este viernes, el presidente del gobierno, pedr...\n",
       "2    el ministro del interior, fernando grande-marl...\n",
       "3    son días muy duros para la familia de olivia y...\n",
       "4    sólo quedan 10 presos de eta por recibir los b...\n",
       "Name: cuerpo, dtype: object"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "68826c08-99d2-48ec-9b1b-69ab18260104",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dos semanas después de su puesta de largo y presentación en sociedad, el primer submarino s-80 para la armada, el s-81 \"isaac peral\", ha entrado hoy en el agua tras una delicada y larga maniobra que se ha retrasado varios días por las condiciones meteorológicas. de esta forma, tras completar su construcción 17 años después de que arrancara el programa, navantia ha cumplido otro importante hito.españa.submarino s-80 tras 17 años y 3.900 millones, el \"isaac peral\" ya está aquíespaña.el comandante '"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#muestra de las noticias (solo las primeras 500 palabras)\n",
    "textos[0][:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7e9c47-731d-4212-a2cd-50d0b39c0f45",
   "metadata": {},
   "source": [
    "## Probabilidades"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1d206a-7825-427b-9361-f1d840ba366a",
   "metadata": {},
   "source": [
    "### Matriz de conteo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "119ca43e-9fe0-4e41-ae98-2ac5db6fbff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos el diccionario de probabilidad\n",
    "# key: (w(t-1), w(t+1)), value: {w(t): count(w(t))}\n",
    "probs = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "7d34ca0c-5143-4349-a32f-68d4b41f5e6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[47m\u001b[32m100%|██████████\u001b[0m \u001b[36m58424/58424 [06:03<00:00]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Separador\n",
    "#variable de formato de la barra de progreso\n",
    "bar_format_ = (f'{Back.WHITE}{Fore.GREEN}{{l_bar}}{{bar}}{Style.RESET_ALL} '\n",
    "               f'{Fore.CYAN}{{n_fmt}}/{{total_fmt}} '\n",
    "               f'[{{elapsed}}<{{remaining}}]{Style.RESET_ALL}'\n",
    "            )\n",
    "for doc in tqdm(textos, bar_format=bar_format_, desc='Creando matriz: '):\n",
    "    #Separamos cada noticia por puntos\n",
    "    lineas = doc.split('.')\n",
    "    for linea in lineas:\n",
    "        #Tokenizamos cada línea\n",
    "        tokens = word_tokenize(linea, language='spanish')\n",
    "        #Mostramos los tokens\n",
    "        #print(tokens)   #Este proceso tarda bastante, se hace a modo de prueba\n",
    "        #Condicionamos las palabras finales\n",
    "        if len(tokens) >= 2:\n",
    "            for i in range(len(tokens) - 2):\n",
    "                t_0 = tokens[i]  #palabra anterior\n",
    "                t_1 = tokens[i+1]  #palabra actual\n",
    "                t_2 = tokens[i+2]  #palabra siguiente\n",
    "                #Creamos la clave del diccionario\n",
    "                key = (t_0, t_2)\n",
    "                #preguntamos si la clave no está en el diccionario\n",
    "                if key not in probs:\n",
    "                    #asinamos una clave vacía\n",
    "                    probs[key] = {}\n",
    "                #preguntamos si la palabra actual no es una clave\n",
    "                if t_1 not in probs[key]:\n",
    "                    #asignamos valor inicial de 1 al diciconario de valores de las probs\n",
    "                    probs[key][t_1] = 1\n",
    "                else:\n",
    "                    #sumamos el valor de aparición de la palabra actual\n",
    "                    probs[key][t_1] += 1\n",
    "                \n",
    "#mostramos las líneas a modo de prueba\n",
    "#lineas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "94510e40-840f-4180-9dc9-02a8346520e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('dos', 'después'): {'semanas': 95,\n",
       "  'años': 283,\n",
       "  'días': 296,\n",
       "  'meses': 208,\n",
       "  'horas': 35,\n",
       "  'siglos': 4,\n",
       "  'minutos': 4,\n",
       "  'décadas': 16,\n",
       "  'elecciones': 2,\n",
       "  'día': 3,\n",
       "  'jornadas': 2,\n",
       "  'legislaturas': 1,\n",
       "  'domingos': 1,\n",
       "  'negocios': 1,\n",
       "  'pasiones': 1,\n",
       "  'decenios': 1,\n",
       "  'iniciativas': 1,\n",
       "  'dispositivos': 1}}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mostramos el diccionario probs, pero solo una parte para hacer corto el proceso\n",
    "dict(islice(probs.items(),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ed41c388-ffde-4c63-ac67-06f3a1c63317",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4875993"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6655764d-47d6-40ec-9933-26e2ef266d0b",
   "metadata": {},
   "source": [
    "### Normalización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "934306e6-9a3a-4ba5-a3e5-669b5515b07f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[47m\u001b[32mNormalizando: 100%|██████████\u001b[0m \u001b[36m4875993/4875993 [00:21<00:00]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Creamos una copia del diccionario para mantener los datos\n",
    "d_probs = probs.copy()\n",
    "#Recorremos las claves y los valores del diccionario probs\n",
    "for key, d in tqdm(d_probs.items(), bar_format=bar_format_, desc='Normalizando: '):\n",
    "    #sumamos los valores de repetición de cada una de las palabras\n",
    "    total = sum(d.values())\n",
    "    #Recorremos la clave y el valor del diccionario de los valores creado\n",
    "    for k, v in d.items():\n",
    "        d[k] = v / total    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "627f4046-8ff5-4408-b090-90c994e1785e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('dos', 'después'): {'semanas': 0.09947643979057591,\n",
       "  'años': 0.2963350785340314,\n",
       "  'días': 0.3099476439790576,\n",
       "  'meses': 0.21780104712041884,\n",
       "  'horas': 0.03664921465968586,\n",
       "  'siglos': 0.004188481675392671,\n",
       "  'minutos': 0.004188481675392671,\n",
       "  'décadas': 0.016753926701570682,\n",
       "  'elecciones': 0.0020942408376963353,\n",
       "  'día': 0.0031413612565445027,\n",
       "  'jornadas': 0.0020942408376963353,\n",
       "  'legislaturas': 0.0010471204188481676,\n",
       "  'domingos': 0.0010471204188481676,\n",
       "  'negocios': 0.0010471204188481676,\n",
       "  'pasiones': 0.0010471204188481676,\n",
       "  'decenios': 0.0010471204188481676,\n",
       "  'iniciativas': 0.0010471204188481676,\n",
       "  'dispositivos': 0.0010471204188481676}}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mostramos el diccionario d_probs, pero solo una parte para hacer corto el proceso\n",
    "dict(islice(d_probs.items(),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "1ce90191-dd0e-4782-bf51-05db6c7c20e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4875993"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(d_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6359898-4004-479f-9635-8061d9ce03fc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Ejemplo de Detokenización\n",
    "\n",
    "Permite volver a unir los tokens en frases, por ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "ed1cf567-d714-4595-b4de-f1332b94158d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frase original: Bootcamp de Inteligencia Artificial\n",
      "Frase tokenizada: ['Bootcamp', 'de', 'Inteligencia', 'Artificial']\n",
      "Frase Detokenizada: Bootcamp de Inteligencia Artificial\n"
     ]
    }
   ],
   "source": [
    "detokenizar = TreebankWordDetokenizer()\n",
    "ejemplo = 'Bootcamp de Inteligencia Artificial'\n",
    "print(f'Frase original: {ejemplo}')\n",
    "token_ejemplo = word_tokenize(ejemplo, language='spanish')\n",
    "print(f'Frase tokenizada: {token_ejemplo}')\n",
    "detoken_ejemplo = detokenizar.detokenize(token_ejemplo)\n",
    "print(f'Frase Detokenizada: {detoken_ejemplo}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616f5b23-0f3a-4eab-befb-ad801331b1cf",
   "metadata": {},
   "source": [
    "## Spinner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "24adfc1a-fcbe-47db-a6e8-332a7f2c8ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función de prueba para una palabra random\n",
    "def sample_word(d):\n",
    "    p0 = np.random.random()\n",
    "    cumulative = 0\n",
    "    for key, p in d.items():\n",
    "        cumulative += p\n",
    "        if p0 < cumulative:\n",
    "            return key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "eda6d4d3-6c5a-4059-8c8a-bfcb46bf8c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función spinner para una línea\n",
    "# CADA COMENTARIO DONDE ESTÁ EL RETURN ES UN EJEMPLO PARA IR ANALIZANDO EL CÓDIGO\n",
    "def spin_line(linea, imp):\n",
    "    tokens = word_tokenize(linea, language='spanish')\n",
    "    i = 0\n",
    "    salida = [tokens[0]]    \n",
    "    #return salida #ejemplo de ejecución --- comentar\n",
    "    if len(tokens) >= 2:\n",
    "        while i < (len(tokens) - 2):\n",
    "            t_0 = tokens[i]   #palabra anterior\n",
    "            t_1 = tokens[i+1] #palabra actual\n",
    "            t_2 = tokens[i+2] #palabra siguiente\n",
    "            #creamos la clave\n",
    "            key = (t_0, t_2)\n",
    "            #creamos el diccionario de distribución\n",
    "            p_dist = d_probs[key]\n",
    "            #i = 1100000   #Para desbordar el while ----- comentar\n",
    "            #return p_dist   #ejemplo de ejecución  ---- comentar \n",
    "            #Cuando el diccionario tenga más de una palabra y un spinning del x%\n",
    "            if len(p_dist) > 1 and np.random.random() < 0.3:\n",
    "                #selecciona una palabra al azar de la función de prueba de palabras\n",
    "                middle = sample_word(p_dist)\n",
    "                #i = 1100000   #Para desbordar el while ----- comentar\n",
    "                #return middle   #ejemplo de ejecución  ---- comentar\n",
    "\n",
    "                #Validamos si deseamos mostrar la palabra de cambio automáticamente\n",
    "                # Si imp es True, muestra el texto cambiado\n",
    "                # Si imp es False, muestra la palabra actual y el cambio que sugiere\n",
    "                if imp:\n",
    "                    #agregamos la palabra nueva en la posición t_1\n",
    "                    salida.append(middle)\n",
    "                    #agregamos la palabra t_2, que va al final\n",
    "                    salida.append(t_2)\n",
    "                    #movemos el cursor 2 posici. para que no haga 2 spin en 2 pal. seguidas\n",
    "                    i += 2\n",
    "                else:                \n",
    "                    #agregamos a la salida la palabra t_1, es decir la que queremos cambiar\n",
    "                    salida.append(t_1)\n",
    "                    #agregamos, para visualizar, la palabra por la que nos va a cambiar\n",
    "                    salida.append('<' + middle + '>')  \n",
    "                    #agregamos la palabra t_2, que va al final\n",
    "                    salida.append(t_2)\n",
    "                    #movemos el cursor dos posici. para que no haga dos spin en 2 pal seguidas\n",
    "                    i += 2\n",
    "            #en caso que el diccionario sea <= 1 o que el random no entre al spinner\n",
    "            else:\n",
    "                #agregamos la palabra siguiente y ubicamos el cursor en la siguiente palabra\n",
    "                salida.append(t_1)\n",
    "                i += 1\n",
    "        # si ya estamos en la última palabra a poner a prueba\n",
    "        if i == len(tokens) - 2:\n",
    "            #agregamos la última palabra al diccionario\n",
    "            salida.append(tokens[-1])\n",
    "        # retornamos la salida detokenizada ya que es una lista ESTE NO SE COMENTA, ES EL FIN\n",
    "        detoken = detokenizar.detokenize(salida)\n",
    "        return detoken "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "dc449d05-7591-4aaa-b24c-46e76ecdb0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función spinner para recorrer el documento\n",
    "def spin_document(doc, imp):\n",
    "    lineas = doc.split('.')\n",
    "    output = []\n",
    "    for linea in lineas:\n",
    "        if linea:\n",
    "            new_line = spin_line(linea, imp)\n",
    "        else:\n",
    "            new_line = linea\n",
    "        output.append(new_line)\n",
    "    #corregimos el posible error de tener cadenas en None\n",
    "    try:\n",
    "        return '\\n'.join(output)\n",
    "    except Exception:\n",
    "        return '\\n'.join(filter(None, output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "b2c750df-bf98-48ce-b90a-1d6570716c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Código para pruebas de creación\n",
    "#spin_document('dos años después cómo están')\n",
    "#spin_line('dos años después cómo están')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf626ba-e375-4602-a329-746a63905f8f",
   "metadata": {},
   "source": [
    "## Texto (noticia) de prueba para el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "7d0d54b8-decd-410f-8967-8820145edd7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    dos semanas después de su puesta de largo y pr...\n",
       "1    este viernes, el presidente del gobierno, pedr...\n",
       "2    el ministro del interior, fernando grande-marl...\n",
       "3    son días muy duros para la familia de olivia y...\n",
       "4    sólo quedan 10 presos de eta por recibir los b...\n",
       "Name: cuerpo, dtype: object"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Recordemos qué tenía nuestro df textos\n",
    "textos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "bfdfe4d6-5089-40cf-a1cd-cb7a6dd41237",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Índice seleccionado:** 35576"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Texto seleccionado:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "un centenar de taxistas se han concentrado a las 8,00 horas de este viernes en la entrada del cementerio de la almudena de madrid y, pasada esta hora, tenían bloqueada la zona. esta acción se produce en el marco de las protestas que está protagonizando el colectivo desde el pasado lunes por la regulación del sector. se trata de la primera acción del día, que ira acompañada de otras como el comienzo de la huelga de hambre que van a iniciar 16 compañeros a partir de las 10,00 horas de hoy en los alrededores de ifema, centro de operaciones de...\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Texto Spinning:**\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "un centenar de taxistas se han concentrado a las 2,00 horas de este campo en la entrada del cementerio de la almudena de presentarlo y la pasada esta hora, tenían bloqueada la zona esta cifra se produce en el toque de las protestas que está protagonizando el colectivo según el próximo lunes por una regulación del sector se trate de la primera acción del día después que ira acompañada de otras sin el comienzo de la historia de hambre que maltratan a iniciar 16 compañeros a cambio de las 10,00 horas de hoy mantener los sistemas de ifema, instructor de...\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#seleccionamos un índice cualquiera de alguna noticia del df textos\n",
    "i = np.random.choice(textos.shape[0])\n",
    "display(Markdown('---'))\n",
    "display(Markdown(f'**Índice seleccionado:** {i}'))\n",
    "display(Markdown('---'))\n",
    "#tomamos el texto que se encuentra en dicho índice\n",
    "doc = textos.iloc[i]\n",
    "#Recortamos el texto, solo para mostrarlo; no se altera el texto inicial\n",
    "doc_recortado = doc.split() #separamos el texto en palabras\n",
    "doc_recortado = ' '.join(doc_recortado[:100])\n",
    "display(Markdown(f'**Texto seleccionado:**'))\n",
    "print(f'{doc_recortado}...')\n",
    "display(Markdown('---'))\n",
    "\n",
    "\n",
    "\n",
    "#Generamos el Spinning Article - Text\n",
    "imp = True\n",
    "new_doc = spin_document(doc, imp)\n",
    "\n",
    "\n",
    "\n",
    "#Recortamos el nuevo texto, solo para mostrarlo; no se altera el texto generado por el spin\n",
    "new_doc_recortado = new_doc.split() #separamos el texto en palabras\n",
    "new_doc_recortado = ' '.join(new_doc_recortado[:100])\n",
    "display(Markdown(f'**Texto Spinning:**\\n\\n'))\n",
    "print(f'{new_doc_recortado}...')\n",
    "display(Markdown('---'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388468e5-871d-4ecf-bbcb-1806c252c538",
   "metadata": {},
   "source": [
    "### Errores de tipo NoneType - Análisis\n",
    "\n",
    "Cuando existe un valor None en el output de la función spin_document, no se puede definir el nuevo texto sugerido. Para solucionar, basta con filtrar el output antes de hacer el join.\n",
    "\n",
    "                            '\\n'.join(filter(None, output))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56c4d73-dfa6-4cd6-a80b-24115fa3de97",
   "metadata": {},
   "source": [
    "## Conclusiones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd3c383-47ab-48d4-bb06-16edf6d0c28c",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <p>El Article Spinning, permite realizar cambios de palabras con el fin de brindar otra opción a un texto ya construido y cambiarle sus palabras de modo que conserve la idea contextual, pero con otro estilo de escritura. El uso de N-Grams através de las cadenas de Markov, permiten utilizar las probabilidades de ocurrencia de una palabra cuando ésta se encuentra en medio de dos palabras previamente entrenadas. Aunque el modelo es bueno, se requiere de un filtro de fuentes más preciso de un tema en específico, pero este es un sencillo ejemplo que nos deja el desafío de usar Spinning Text dentro de NPL.</p>\n",
    "    <hr/>\n",
    "    <p style=\"text-align: right;\">Mg. Luis Felipe Bustamante Narváez</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a18d5e-7f29-4c7e-81e0-b0650e07c389",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
